{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# AIT Development notebook\n",
    "\n",
    "\n",
    "## notebook of structure\n",
    "\n",
    "|#|area name|cell num|description|edit or not|\n",
    "|---|---|---|---|---|\n",
    "| 1|flags set|1|setting of launch jupyter or ait flag.|no edit|\n",
    "| 2|ait-sdk install|1|Use only jupyter launch.<br>find ait-sdk and install.|no edit|\n",
    "| 3|create requirements and pip install|3|Use only jupyter launch.<br>create requirements.txt.<br>And install by requirements.txt.|should edit(second cell, you set use modules.)|\n",
    "| 4|import|2|you should write use import modules.<br>but bottom lines do not edit.|should edit(first cell, you import your moduel.)|\n",
    "| 5|create manifest|1|Use only jupyter launch.<br>create ait.manifest.json.|should edit|\n",
    "| 6|create input|1|Use only jupyter launch.<br>create ait.input.json.|should edit|\n",
    "| 7|initialize|1|this cell is initialize for ait progress.|no edit|\n",
    "| 8|functions|N|you defined measures, resources, downloads in ait.manifesit.json. <br>Define any functions to add these.|should edit|\n",
    "| 9|main|1|Read the data set or model and calls the function defined in `functions-area`.|should edit|\n",
    "|10|entrypoint|1|Call the main function.|no edit|\n",
    "|11|license attribute set|1|Use only notebook launch.<br>Setting attribute for license.|should edit|\n",
    "|12|prepare deploy|1|Use only notebook launch.<br>Convert to python programs and create dag.py.|no edit|\n",
    "\n",
    "## notebook template revision history\n",
    "\n",
    "### 1.0.1 2020/10/21\n",
    "\n",
    "* add revision history\n",
    "* separate `create requirements and pip install` editable and noeditable\n",
    "* separate `import` editable and noeditable\n",
    "\n",
    "### 1.0.0 2020/10/12\n",
    "\n",
    "* new cerarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:flags set\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "# Determine whether to start AIT or jupyter by startup argument\n",
    "import sys\n",
    "is_ait_launch = (len(sys.argv) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.2.4)\n",
      "Processing ./ait_sdk-0.1.4-py3-none-any.whl\n",
      "Collecting psutil<=5.7.3\n",
      "  Downloading psutil-5.7.3.tar.gz (465 kB)\n",
      "\u001b[K     |████████████████████████████████| 465 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<=1.19.3\n",
      "  Downloading numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 10.7 MB/s eta 0:00:01   |█▉                              | 860 kB 8.4 MB/s eta 0:00:02     |████████████████▏               | 7.5 MB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbformat<=5.0.8\n",
      "  Using cached nbformat-5.0.8-py3-none-any.whl (172 kB)\n",
      "Collecting nbconvert<=6.0.7\n",
      "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting keras<=2.4.3\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting py-cpuinfo<=7.0.0\n",
      "  Downloading py-cpuinfo-7.0.0.tar.gz (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 6.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ipython-genutils\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting traitlets>=4.1\n",
      "  Using cached traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting jupyter-core\n",
      "  Downloading jupyter_core-4.7.0-py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.4.3.tar.gz (16 kB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-3.2.1-py2.py3-none-any.whl (145 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Using cached nbclient-0.5.1-py3-none-any.whl (65 kB)\n",
      "Collecting testpath\n",
      "  Using cached testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pygments>=2.4.1\n",
      "  Downloading Pygments-2.7.2-py3-none-any.whl (948 kB)\n",
      "\u001b[K     |████████████████████████████████| 948 kB 15.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2>=2.4\n",
      "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 11.4 MB/s eta 0:00:01    |██▋                             | 2.1 MB 10.7 MB/s eta 0:00:03     |█████████████▎                  | 10.7 MB 10.7 MB/s eta 0:00:02     |███████████████████▊            | 16.0 MB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.11.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-50.3.2-py3-none-any.whl (785 kB)\n",
      "Processing /root/.cache/pip/wheels/34/13/19/294da8e11bce7e563afee51251b9fa878185e14f4b5caf00cb/pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting decorator\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting jupyter-client>=6.1.5\n",
      "  Using cached jupyter_client-6.1.7-py3-none-any.whl (108 kB)\n",
      "Collecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
      "Collecting async-generator\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Using cached MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting tornado>=4.1\n",
      "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
      "\u001b[K     |████████████████████████████████| 427 kB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pyzmq>=13\n",
      "  Downloading pyzmq-20.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: psutil, py-cpuinfo, pandocfilters, pyyaml\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.3-cp36-cp36m-linux_x86_64.whl size=288556 sha256=bc96f24170ef69457a555f1754a84d1fb13124ded44dd7df9cd4b924c90ffac4\n",
      "  Stored in directory: /root/.cache/pip/wheels/fa/ad/67/90bbaacdcfe970960dd5158397f23a6579b51d853720d7856d\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-py3-none-any.whl size=20299 sha256=9bf50dc5ffce03ff61573c72065d222883e99998846bbb8376a2c845b12fa194\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/6d/cc/73a126dc2e09fe56fcec0a7386d255762611fbed1c86d3bbcc\n",
      "  Building wheel for pandocfilters (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandocfilters: filename=pandocfilters-1.4.3-py3-none-any.whl size=10627 sha256=8ea277e5afa755beafa424d6f2b7a5d4b9613f32d4e2584fe403f22c1e76bc90\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/12/89/fe63ac4d6ee6440daab4db77b78c63f7f192b700f844b6639f\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=45919 sha256=f63d38931b49282cc8a87e12ac3338b93089b364de32c1133630d8df69fa3a71\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc\n",
      "Successfully built psutil py-cpuinfo pandocfilters pyyaml\n",
      "Installing collected packages: psutil, numpy, ipython-genutils, zipp, importlib-metadata, attrs, six, setuptools, pyrsistent, jsonschema, decorator, traitlets, jupyter-core, nbformat, mistune, pandocfilters, entrypoints, pyparsing, packaging, webencodings, bleach, tornado, python-dateutil, pyzmq, jupyter-client, nest-asyncio, async-generator, nbclient, testpath, defusedxml, pygments, jupyterlab-pygments, MarkupSafe, jinja2, nbconvert, cached-property, h5py, scipy, pyyaml, keras, py-cpuinfo, ait-sdk\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Attempting uninstall: ipython-genutils\n",
      "    Found existing installation: ipython-genutils 0.2.0\n",
      "    Uninstalling ipython-genutils-0.2.0:\n",
      "      Successfully uninstalled ipython-genutils-0.2.0\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.1.0\n",
      "    Uninstalling zipp-3.1.0:\n",
      "      Successfully uninstalled zipp-3.1.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 20.2.0\n",
      "    Uninstalling attrs-20.2.0:\n",
      "      Successfully uninstalled attrs-20.2.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 50.3.2\n",
      "    Uninstalling setuptools-50.3.2:\n",
      "      Successfully uninstalled setuptools-50.3.2\n",
      "  Attempting uninstall: pyrsistent\n",
      "    Found existing installation: pyrsistent 0.17.3\n",
      "    Uninstalling pyrsistent-0.17.3:\n",
      "      Successfully uninstalled pyrsistent-0.17.3\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 3.2.0\n",
      "    Uninstalling jsonschema-3.2.0:\n",
      "      Successfully uninstalled jsonschema-3.2.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 4.3.3\n",
      "    Uninstalling traitlets-4.3.3:\n",
      "      Successfully uninstalled traitlets-4.3.3\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.6.3\n",
      "    Uninstalling jupyter-core-4.6.3:\n",
      "      Successfully uninstalled jupyter-core-4.6.3\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.0.8\n",
      "    Uninstalling nbformat-5.0.8:\n",
      "      Successfully uninstalled nbformat-5.0.8\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: pandocfilters\n",
      "    Found existing installation: pandocfilters 1.4.2\n",
      "    Uninstalling pandocfilters-1.4.2:\n",
      "      Successfully uninstalled pandocfilters-1.4.2\n",
      "  Attempting uninstall: entrypoints\n",
      "    Found existing installation: entrypoints 0.3\n",
      "    Uninstalling entrypoints-0.3:\n",
      "      Successfully uninstalled entrypoints-0.3\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.4\n",
      "    Uninstalling packaging-20.4:\n",
      "      Successfully uninstalled packaging-20.4\n",
      "  Attempting uninstall: webencodings\n",
      "    Found existing installation: webencodings 0.5.1\n",
      "    Uninstalling webencodings-0.5.1:\n",
      "      Successfully uninstalled webencodings-0.5.1\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 3.2.1\n",
      "    Uninstalling bleach-3.2.1:\n",
      "      Successfully uninstalled bleach-3.2.1\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.0.4\n",
      "    Uninstalling tornado-6.0.4:\n",
      "      Successfully uninstalled tornado-6.0.4\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 19.0.2\n",
      "    Uninstalling pyzmq-19.0.2:\n",
      "      Successfully uninstalled pyzmq-19.0.2\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 6.1.7\n",
      "    Uninstalling jupyter-client-6.1.7:\n",
      "      Successfully uninstalled jupyter-client-6.1.7\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.4.1\n",
      "    Uninstalling nest-asyncio-1.4.1:\n",
      "      Successfully uninstalled nest-asyncio-1.4.1\n",
      "  Attempting uninstall: async-generator\n",
      "    Found existing installation: async-generator 1.10\n",
      "    Uninstalling async-generator-1.10:\n",
      "      Successfully uninstalled async-generator-1.10\n",
      "  Attempting uninstall: nbclient\n",
      "    Found existing installation: nbclient 0.5.1\n",
      "    Uninstalling nbclient-0.5.1:\n",
      "      Successfully uninstalled nbclient-0.5.1\n",
      "  Attempting uninstall: testpath\n",
      "    Found existing installation: testpath 0.4.4\n",
      "    Uninstalling testpath-0.4.4:\n",
      "      Successfully uninstalled testpath-0.4.4\n",
      "  Attempting uninstall: defusedxml\n",
      "    Found existing installation: defusedxml 0.6.0\n",
      "    Uninstalling defusedxml-0.6.0:\n",
      "      Successfully uninstalled defusedxml-0.6.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.7.1\n",
      "    Uninstalling Pygments-2.7.1:\n",
      "      Successfully uninstalled Pygments-2.7.1\n",
      "  Attempting uninstall: jupyterlab-pygments\n",
      "    Found existing installation: jupyterlab-pygments 0.1.2\n",
      "    Uninstalling jupyterlab-pygments-0.1.2:\n",
      "      Successfully uninstalled jupyterlab-pygments-0.1.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 2.11.2\n",
      "    Uninstalling Jinja2-2.11.2:\n",
      "      Successfully uninstalled Jinja2-2.11.2\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.0.7\n",
      "    Uninstalling nbconvert-6.0.7:\n",
      "      Successfully uninstalled nbconvert-6.0.7\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.3.0 requires h5py<2.11.0,>=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\n",
      "tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.3 which is incompatible.\n",
      "tensorflow 2.3.0 requires scipy==1.4.1, but you'll have scipy 1.5.4 which is incompatible.\u001b[0m\n",
      "Successfully installed MarkupSafe-1.1.1 ait-sdk-0.1.4 async-generator-1.10 attrs-20.3.0 bleach-3.2.1 cached-property-1.5.2 decorator-4.4.2 defusedxml-0.6.0 entrypoints-0.3 h5py-3.1.0 importlib-metadata-2.0.0 ipython-genutils-0.2.0 jinja2-2.11.2 jsonschema-3.2.0 jupyter-client-6.1.7 jupyter-core-4.7.0 jupyterlab-pygments-0.1.2 keras-2.4.3 mistune-0.8.4 nbclient-0.5.1 nbconvert-6.0.7 nbformat-5.0.8 nest-asyncio-1.4.3 numpy-1.19.3 packaging-20.4 pandocfilters-1.4.3 psutil-5.7.3 py-cpuinfo-7.0.0 pygments-2.7.2 pyparsing-2.4.7 pyrsistent-0.17.3 python-dateutil-2.8.1 pyyaml-5.3.1 pyzmq-20.0.0 scipy-1.5.4 setuptools-50.3.2 six-1.15.0 testpath-0.4.4 tornado-6.1 traitlets-4.3.3 webencodings-0.5.1 zipp-3.4.0\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:ait-sdk install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    # get ait-sdk file name\n",
    "    from pathlib import Path\n",
    "    from glob import glob\n",
    "    import re\n",
    "\n",
    "    def numericalSort(value):\n",
    "        numbers = re.compile(r'(\\d+)')\n",
    "        parts = numbers.split(value)\n",
    "        parts[1::2] = map(int, parts[1::2])\n",
    "        return parts\n",
    "    latest_sdk_file_path=sorted(glob('../lib/*.whl'), key=numericalSort)[-1]\n",
    "\n",
    "    ait_sdk_name = Path(latest_sdk_file_path).name\n",
    "    \n",
    "    # copy to develop dir\n",
    "    import shutil\n",
    "    current_dir = %pwd\n",
    "    shutil.copyfile(f'../lib/{ait_sdk_name}', f'{current_dir}/{ait_sdk_name}')\n",
    "\n",
    "    # install ait-sdk\n",
    "    !pip install --upgrade pip\n",
    "    !pip install --force-reinstall ./$ait_sdk_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_requirements_generator import AITRequirementsGenerator\n",
    "    requirements_generator = AITRequirementsGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package('bleach','1.5.0')\n",
    "    requirements_generator.add_package('cycler','0.10.0')\n",
    "    requirements_generator.add_package('decorator','4.1.2')\n",
    "    requirements_generator.add_package('h5py','2.9.0')\n",
    "    requirements_generator.add_package('html5lib','0.9999999')\n",
    "    requirements_generator.add_package('Keras','2.0.8')\n",
    "    requirements_generator.add_package('Markdown','2.6.9')\n",
    "    requirements_generator.add_package('matplotlib','2.0.2')\n",
    "    requirements_generator.add_package('networkx','1.11')\n",
    "    requirements_generator.add_package('numpy','1.13.3')\n",
    "    requirements_generator.add_package('olefile','0.44')\n",
    "    requirements_generator.add_package('pandas','0.20.3')\n",
    "    requirements_generator.add_package('Pillow','4.3.0')\n",
    "    requirements_generator.add_package('protobuf','3.6.1')\n",
    "    requirements_generator.add_package('pyparsing','2.2.0')\n",
    "    requirements_generator.add_package('python-dateutil','2.6.1')\n",
    "    requirements_generator.add_package('pytz','2017.2')\n",
    "    requirements_generator.add_package('PyWavelets','0.5.2')\n",
    "    requirements_generator.add_package('PyYAML','3.12')\n",
    "    requirements_generator.add_package('scikit-image','0.14.2')\n",
    "    requirements_generator.add_package('scikit-learn','0.19.0')\n",
    "    requirements_generator.add_package('scipy','0.19.1')\n",
    "    requirements_generator.add_package('six','1.11.0')\n",
    "    requirements_generator.add_package('tensorflow','1.13.1')\n",
    "    requirements_generator.add_package('tensorflow-tensorboard','0.1.6')\n",
    "    requirements_generator.add_package('Werkzeug','0.12.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bleach==1.5.0\n",
      "  Downloading bleach-1.5.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 2)) (0.10.0)\n",
      "Collecting decorator==4.1.2\n",
      "  Downloading decorator-4.1.2-py2.py3-none-any.whl (9.1 kB)\n",
      "Collecting h5py==2.9.0\n",
      "  Downloading h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting html5lib==0.9999999\n",
      "  Downloading html5lib-0.9999999.tar.gz (889 kB)\n",
      "\u001b[K     |████████████████████████████████| 889 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Keras==2.0.8\n",
      "  Downloading Keras-2.0.8-py2.py3-none-any.whl (276 kB)\n",
      "\u001b[K     |████████████████████████████████| 276 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Markdown==2.6.9\n",
      "  Downloading Markdown-2.6.9.tar.gz (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 11.0 MB/s eta 0:00:01     |██████████████████              | 153 kB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib==2.0.2\n",
      "  Downloading matplotlib-2.0.2-cp36-cp36m-manylinux1_x86_64.whl (14.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.6 MB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx==1.11\n",
      "  Downloading networkx-1.11-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.13.3\n",
      "  Downloading numpy-1.13.3-cp36-cp36m-manylinux1_x86_64.whl (17.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.0 MB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting olefile==0.44\n",
      "  Downloading olefile-0.44.zip (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 4.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.20.3\n",
      "  Downloading pandas-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (24.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.5 MB 9.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting Pillow==4.3.0\n",
      "  Downloading Pillow-4.3.0-cp36-cp36m-manylinux1_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf==3.6.1\n",
      "  Downloading protobuf-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing==2.2.0\n",
      "  Downloading pyparsing-2.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil==2.6.1\n",
      "  Downloading python_dateutil-2.6.1-py2.py3-none-any.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz==2017.2\n",
      "  Downloading pytz-2017.2-py2.py3-none-any.whl (484 kB)\n",
      "\u001b[K     |████████████████████████████████| 484 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets==0.5.2\n",
      "  Downloading PyWavelets-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyYAML==3.12\n",
      "  Downloading PyYAML-3.12.tar.gz (253 kB)\n",
      "\u001b[K     |████████████████████████████████| 253 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image==0.14.2\n",
      "  Downloading scikit_image-0.14.2-cp36-cp36m-manylinux1_x86_64.whl (25.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3 MB 11.8 MB/s eta 0:00:01     |████████████████████▌           | 16.2 MB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==0.19.0\n",
      "  Downloading scikit_learn-0.19.0-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 13.2 MB/s eta 0:00:01   |████████████                    | 4.6 MB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy==0.19.1\n",
      "  Downloading scipy-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (48.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.2 MB 12.8 MB/s eta 0:00:01     |██████████████████████▋         | 34.1 MB 9.9 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting six==1.11.0\n",
      "  Downloading six-1.11.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tensorflow==1.13.1\n",
      "  Downloading tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 92.5 MB 9.9 MB/s eta 0:00:011     |█████▋                          | 16.3 MB 12.1 MB/s eta 0:00:07     |███████████▉                    | 34.3 MB 11.2 MB/s eta 0:00:06     |███████████████                 | 43.6 MB 11.2 MB/s eta 0:00:05     |██████████████████▌             | 53.5 MB 11.2 MB/s eta 0:00:04     |██████████████████████▏         | 64.0 MB 9.2 MB/s eta 0:00:04     |█████████████████████████▌      | 73.8 MB 10.3 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting tensorflow-tensorboard==0.1.6\n",
      "  Downloading tensorflow_tensorboard-0.1.6-py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Werkzeug==0.12.2\n",
      "  Downloading Werkzeug-0.12.2-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ait-sdk==0.1.4 from file:///workdir/root/develop/ait_sdk-0.1.4-py3-none-any.whl in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 27)) (0.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf==3.6.1->-r /workdir/root/develop/requirements.txt (line 14)) (50.3.2)\n",
      "Collecting cloudpickle>=0.2.1\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting dask[array]>=1.0.0\n",
      "  Downloading dask-2.30.0-py3-none-any.whl (848 kB)\n",
      "\u001b[K     |████████████████████████████████| 848 kB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
      "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 24)) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 24)) (0.30.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 24)) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 24)) (1.30.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
      "\u001b[K     |████████████████████████████████| 367 kB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 24)) (0.9.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 24)) (0.3.3)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: nbformat<=5.0.8 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (5.0.8)\n",
      "Requirement already satisfied: psutil<=5.7.3 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (5.7.3)\n",
      "Requirement already satisfied: nbconvert<=6.0.7 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (6.0.7)\n",
      "Requirement already satisfied: py-cpuinfo<=7.0.0 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (7.0.0)\n",
      "Collecting toolz>=0.8.2; extra == \"array\"\n",
      "  Downloading toolz-0.11.1-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mock>=2.0.0\n",
      "  Downloading mock-4.0.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (4.3.3)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (4.7.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (3.2.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (2.11.2)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (2.7.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (1.4.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (0.4.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (0.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (0.5.1)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (0.6.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (2.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (0.17.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (1.1.1)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (1.10)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (6.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (1.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (3.4.0)\n",
      "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (6.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 27)) (20.0.0)\n",
      "Building wheels for collected packages: html5lib, Markdown, olefile, PyYAML\n",
      "  Building wheel for html5lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html5lib: filename=html5lib-0.9999999-py3-none-any.whl size=111295 sha256=555ec1376a33b0fad27a6f7070b43287ce7568b2778c5456085b72e3da635817\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/1c/cb/a87fd097ff74648ecc468a703001f6c7c86d8a71d459e65c98\n",
      "  Building wheel for Markdown (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Markdown: filename=Markdown-2.6.9-py3-none-any.whl size=163233 sha256=b1ec7228864e3c63f1d9b71351d5862bab549990c0610b422f834dd57f181e7a\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/55/17/f129d80a5d263161d52b3c282fd818317dc95986535b7ee24a\n",
      "  Building wheel for olefile (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for olefile: filename=olefile-0.44-py3-none-any.whl size=52631 sha256=61c75900e057b8283020c7d4b48151b69a141c5120b796326a1f1cea7583b809\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/77/c6/3d974ba3cb5825fb376485fc5abd5c7a427b85b187a611fecc\n",
      "  Building wheel for PyYAML (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-3.12-cp36-cp36m-linux_x86_64.whl size=43458 sha256=d77619c1a3440ba0e5520ba74c0bfc6ddf62052a2a6be1afb14a1ceb4f4b001a\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/06/c3/a48dc77c7d8f60b64eaf0fffd5ee5ab8abce5d13893b73109b\n",
      "Successfully built html5lib Markdown olefile PyYAML\n",
      "Installing collected packages: six, html5lib, bleach, decorator, numpy, h5py, scipy, PyYAML, Keras, Markdown, python-dateutil, pyparsing, pytz, matplotlib, networkx, olefile, pandas, Pillow, protobuf, PyWavelets, cloudpickle, toolz, dask, scikit-image, scikit-learn, Werkzeug, tensorboard, keras-applications, mock, tensorflow-estimator, astor, tensorflow, tensorflow-tensorboard\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 3.2.1\n",
      "    Uninstalling bleach-3.2.1:\n",
      "      Successfully uninstalled bleach-3.2.1\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.3\n",
      "    Uninstalling numpy-1.19.3:\n",
      "      Successfully uninstalled numpy-1.19.3\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.3.1\n",
      "    Uninstalling PyYAML-5.3.1:\n",
      "      Successfully uninstalled PyYAML-5.3.1\n",
      "  Attempting uninstall: Keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "  Attempting uninstall: Markdown\n",
      "    Found existing installation: Markdown 3.2.2\n",
      "    Uninstalling Markdown-3.2.2:\n",
      "      Successfully uninstalled Markdown-3.2.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.3.2\n",
      "    Uninstalling matplotlib-3.3.2:\n",
      "      Successfully uninstalled matplotlib-3.3.2\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.0.0\n",
      "    Uninstalling Pillow-8.0.0:\n",
      "      Successfully uninstalled Pillow-8.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.12.2\n",
      "    Uninstalling protobuf-3.12.2:\n",
      "      Successfully uninstalled protobuf-3.12.2\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.3.0\n",
      "    Uninstalling tensorboard-2.3.0:\n",
      "      Successfully uninstalled tensorboard-2.3.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.3.0\n",
      "    Uninstalling tensorflow-2.3.0:\n",
      "      Successfully uninstalled tensorflow-2.3.0\n",
      "Successfully installed Keras-2.0.8 Markdown-2.6.9 Pillow-4.3.0 PyWavelets-0.5.2 PyYAML-3.12 Werkzeug-0.12.2 astor-0.8.1 bleach-1.5.0 cloudpickle-1.6.0 dask-2.30.0 decorator-4.1.2 h5py-2.9.0 html5lib-0.9999999 keras-applications-1.0.8 matplotlib-2.0.2 mock-4.0.2 networkx-1.11 numpy-1.13.3 olefile-0.44 pandas-0.20.3 protobuf-3.6.1 pyparsing-2.2.0 python-dateutil-2.6.1 pytz-2017.2 scikit-image-0.14.2 scikit-learn-0.19.0 scipy-0.19.1 six-1.11.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 tensorflow-tensorboard-0.1.6 toolz-0.11.1\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package(f'./{ait_sdk_name}')\n",
    "    requirements_path = requirements_generator.create_requirements(current_dir)\n",
    "\n",
    "    !pip install -r $requirements_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:import\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "# import if you need modules cell\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from os import makedirs, path\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from deep_saucer.metamorphic_testing.lib.metamorphic_verification import main as main_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:import\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "# must use modules\n",
    "import shutil  # do not remove\n",
    "from ait_sdk.common.files.ait_input import AITInput  # do not remove\n",
    "from ait_sdk.common.files.ait_output import AITOutput  # do not remove\n",
    "from ait_sdk.common.files.ait_manifest import AITManifest  # do not remove\n",
    "from ait_sdk.develop.ait_path_helper import AITPathHelper  # do not remove\n",
    "from ait_sdk.utils.logging import get_logger, log, get_log_path  # do not remove\n",
    "from ait_sdk.develop.annotation import measures, resources, downloads, ait_main  # do not remove\n",
    "# must use modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create manifest\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_manifest_generator import AITManifestGenerator\n",
    "    \n",
    "    manifest_genenerator = AITManifestGenerator(current_dir)\n",
    "    manifest_genenerator.set_ait_name('eval_metamorphic_test_tf1.13')\n",
    "    manifest_genenerator.set_ait_description('''Metamorphic test.\n",
    "Make sure can be classified in the same result as the original class be added a little processing to the original data.''')\n",
    "    manifest_genenerator.set_ait_author('AIST')\n",
    "    manifest_genenerator.set_ait_email('')\n",
    "    manifest_genenerator.set_ait_version('0.1')\n",
    "    manifest_genenerator.set_ait_quality('https://airc.aist.go.jp/aiqm/quality/internal/Robustness_of_trained_model')\n",
    "    manifest_genenerator.set_ait_reference('')\n",
    "    manifest_genenerator.add_ait_inventories(name='mnist_dataset', \n",
    "                                             type_='dataset', \n",
    "                                             description='MNIST_dataset are train image, train label, test image, test label', \n",
    "                                             format_=['zip'], \n",
    "                                             schema='http://yann.lecun.com/exdb/mnist/')\n",
    "    manifest_genenerator.add_ait_inventories(name='mnist_model', \n",
    "                                             type_='model', \n",
    "                                             description='MNIST_model', \n",
    "                                             format_=['zip'], \n",
    "                                             schema='https://github.com/hitachi-rd-yokohama/deep_saucer')\n",
    "    manifest_genenerator.add_ait_parameters(name='Lap', \n",
    "                                            type_='int', \n",
    "                                            description='Input Data Conversion Number', \n",
    "                                            default_val='10')\n",
    "    manifest_genenerator.add_ait_parameters(name='NumTest', \n",
    "                                            type_='int', \n",
    "                                            description='Number of Test Data to be Used', \n",
    "                                            default_val='500')\n",
    "    manifest_genenerator.add_ait_parameters(name='mnist_type', \n",
    "                                            type_='str', \n",
    "                                            description='train = Training_data, test = test_data, validation = validation_data', \n",
    "                                            default_val='train')\n",
    "    manifest_genenerator.add_ait_measures(name='average', \n",
    "                                          type_='float', \n",
    "                                          description='Average number of NG output', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_resources(name='result', \n",
    "                                           path='/usr/local/qai/resources/1/result.csv', \n",
    "                                           type_='table', \n",
    "                                           description='number of NG output')\n",
    "    manifest_genenerator.add_ait_downloads(name='Log', \n",
    "                                           path='/usr/local/qai/downloads/1/ait.log', \n",
    "                                           description='AIT_log')\n",
    "    manifest_genenerator.add_ait_downloads(name='DeepLog', \n",
    "                                           path='/usr/local/qai/downloads/2/deep.log', \n",
    "                                           description='deep_saucer_log')\n",
    "    manifest_path = manifest_genenerator.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create input\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_input_generator import AITInputGenerator\n",
    "    input_generator = AITInputGenerator(manifest_path)\n",
    "    input_generator.add_ait_inventories(name='mnist_dataset',\n",
    "                                        value='mnist_dataset/mnist_dataset.zip')\n",
    "    input_generator.add_ait_inventories(name='mnist_model',\n",
    "                                        value='mnist_model/model_mnist.zip')\n",
    "    input_generator.set_ait_params(name='Lap',\n",
    "                                   value='10')\n",
    "    input_generator.set_ait_params(name='NumTest',\n",
    "                                   value='500')\n",
    "    input_generator.set_ait_params(name='mnist_type',\n",
    "                                   value='train')\n",
    "    input_generator.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:initialize\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "ait_manifest = AITManifest()\n",
    "ait_input = AITInput(ait_manifest)\n",
    "ait_output = AITOutput(ait_manifest)\n",
    "\n",
    "if is_ait_launch:\n",
    "    # launch from AIT\n",
    "    current_dir = path.dirname(path.abspath(__file__))\n",
    "    path_helper = AITPathHelper(argv=sys.argv, ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "else:\n",
    "    # launch from jupyter notebook\n",
    "    # ait.input.json make in input_dir\n",
    "    input_dir = '/usr/local/qai/mnt/ip/job_args/1/1'\n",
    "    current_dir = %pwd\n",
    "    path_helper = AITPathHelper(argv=['', input_dir], ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "\n",
    "ait_input.read_json(path_helper.get_input_file_path())\n",
    "ait_manifest.read_json(path_helper.get_manifest_file_path())\n",
    "\n",
    "### do not edit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'average')\n",
    "def ng_average(cov):\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@resources(ait_output, path_helper, 'result')\n",
    "def save_result(output_list, file_path: str=None) -> None:\n",
    "    makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        f.writelines(output_list)\n",
    "        #writer = csv.writer(f)\n",
    "        #writer.writerow(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'Log')\n",
    "def move_log(file_path: str=None) -> None:\n",
    "    makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "    \n",
    "    shutil.move(get_log_path(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'DeepLog')\n",
    "def move_deep_log(log_path, file_path: str=None) -> None:\n",
    "    makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "    \n",
    "    shutil.copyfile(log_path, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:main\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@ait_main(ait_output, path_helper)\n",
    "def main() -> None:\n",
    "    \n",
    "    # インベントリを読み込み\n",
    "    detaset_save_dir = ait_input.get_inventory_path('mnist_dataset')\n",
    "    detaset_save_parent_dir = str(Path(detaset_save_dir).parent)\n",
    "    zipfile.ZipFile(detaset_save_dir).extractall(detaset_save_parent_dir)\n",
    "    mnist_dataset = input_data.read_data_sets(detaset_save_parent_dir, one_hot=True)\n",
    "    \n",
    "    # モデルを読み込み\n",
    "    model_path = ait_input.get_inventory_path('mnist_model')\n",
    "    model_parent_path = str(Path(model_path).parent)\n",
    "    zipfile.ZipFile(model_path).extractall(model_parent_path)\n",
    "    model_path = model_parent_path + '/model_mnist.ckpt'\n",
    "    model_name_list = model_parent_path + '/model_mnist.ckpt_name.json'\n",
    "    \n",
    "    # パラメータを読み込み\n",
    "    lap_val = ait_input.get_method_param_value('Lap')\n",
    "    num_test_val = ait_input.get_method_param_value('NumTest')\n",
    "    # json形式のパラメータ\n",
    "    args_json = {\n",
    "      \"NameList\": model_name_list,\n",
    "      \"CompOp\": \"==\",\n",
    "      \"Lap\": lap_val,\n",
    "      \"NumTest\": num_test_val\n",
    "    }\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.import_meta_graph(model_path + '.meta')\n",
    "    saver.restore(sess, str(model_path))\n",
    "    \n",
    "    # 実行\n",
    "    mnist_type = ait_input.get_method_param_value('mnist_type')\n",
    "    if mnist_type == 'train':\n",
    "        result = main_deep(sess, [mnist_dataset.train.images], args_json)\n",
    "    elif mnist_type == 'test':\n",
    "        result = main_deep(sess, [mnist_dataset.test.images], args_json)\n",
    "    elif mnist_type == 'validation':\n",
    "        result = main_deep(sess, [mnist_dataset.validation.images], args_json)\n",
    "    else:\n",
    "        raise Exception('mnist_type error : {} is not define'.format(mnist_type))\n",
    "\n",
    "    # 実行結果から情報をピックアップ\n",
    "    ng_count = 0\n",
    "    output_list = []\n",
    "    with open(result) as f:\n",
    "        for s_line in f:\n",
    "            if 'Lap #' in s_line:\n",
    "                ng_count = ng_count + int(s_line.split(': ')[1])\n",
    "                output_list.append(s_line.replace(':', ','))\n",
    "\n",
    "    cov = ng_count / (num_test_val * lap_val)\n",
    "    \n",
    "    output_list.append('Average number of NG output, {}'.format(cov))\n",
    "    \n",
    "    # resources\n",
    "    save_result(output_list)\n",
    "    # measures\n",
    "    ng_average(cov)\n",
    "    # downloads\n",
    "    move_deep_log(result)\n",
    "    move_log()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /usr/local/qai/inventory/mnist_dataset/train-images-idx3-ubyte.gz\n",
      "Extracting /usr/local/qai/inventory/mnist_dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting /usr/local/qai/inventory/mnist_dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting /usr/local/qai/inventory/mnist_dataset/t10k-labels-idx1-ubyte.gz\n",
      "---------------------\n",
      "Summary (NG Count)\n",
      "---------------------\n",
      "Lap #0: 7\n",
      "Lap #1: 16\n",
      "Lap #2: 27\n",
      "Lap #3: 40\n",
      "Lap #4: 51\n",
      "Lap #5: 66\n",
      "Lap #6: 89\n",
      "Lap #7: 105\n",
      "Lap #8: 122\n",
      "Lap #9: 139\n",
      "---------------------\n",
      "Log File: /workdir/root/develop/logfile/log_2020-11-19_05-31-41.txt\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:entory point\n",
    "# do not edit\n",
    "#########################################\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:license attribute set\n",
    "# should edit\n",
    "#########################################\n",
    "ait_owner='AIST'\n",
    "ait_creation_year='2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:prepare deproy\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.deploy import prepare_deploy\n",
    "    from ait_sdk.license.license_generator import LicenseGenerator\n",
    "    \n",
    "    current_dir = %pwd\n",
    "    prepare_deploy(ait_manifest, ait_sdk_name, current_dir, requirements_path, is_remote_deploy=True)\n",
    "    \n",
    "    # output License.txt\n",
    "    license_generator = LicenseGenerator()\n",
    "    license_generator.write('../top_dir/LICENSE.txt', ait_creation_year, ait_owner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
