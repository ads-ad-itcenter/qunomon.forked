{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# AIT Development notebook\n",
    "\n",
    "\n",
    "## notebook of structure\n",
    "\n",
    "|#|area name|cell num|description|edit or not|\n",
    "|---|---|---|---|---|\n",
    "| 1|flags set|1|setting of launch jupyter or ait flag.|no edit|\n",
    "| 2|ait-sdk install|1|Use only jupyter launch.<br>find ait-sdk and install.|no edit|\n",
    "| 3|create requirements and pip install|3|Use only jupyter launch.<br>create requirements.txt.<br>And install by requirements.txt.|should edit(second cell, you set use modules.)|\n",
    "| 4|import|2|you should write use import modules.<br>but bottom lines do not edit.|should edit(first cell, you import your moduel.)|\n",
    "| 5|create manifest|1|Use only jupyter launch.<br>create ait.manifest.json.|should edit|\n",
    "| 6|create input|1|Use only jupyter launch.<br>create ait.input.json.|should edit|\n",
    "| 7|initialize|1|this cell is initialize for ait progress.|no edit|\n",
    "| 8|functions|N|you defined measures, resources, downloads in ait.manifesit.json. <br>Define any functions to add these.|should edit|\n",
    "| 9|main|1|Read the data set or model and calls the function defined in `functions-area`.|should edit|\n",
    "|10|entrypoint|1|Call the main function.|no edit|\n",
    "|11|license attribute set|1|Use only notebook launch.<br>Setting attribute for license.|should edit|\n",
    "|12|prepare deploy|1|Use only notebook launch.<br>Convert to python programs and create dag.py.|no edit|\n",
    "\n",
    "## notebook template revision history\n",
    "\n",
    "### 1.0.1 2020/10/21\n",
    "\n",
    "* add revision history\n",
    "* separate `create requirements and pip install` editable and noeditable\n",
    "* separate `import` editable and noeditable\n",
    "\n",
    "### 1.0.0 2020/10/12\n",
    "\n",
    "* new cerarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:flags set\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "# Determine whether to start AIT or jupyter by startup argument\n",
    "import sys\n",
    "is_ait_launch = (len(sys.argv) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (21.1.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Processing ./ait_sdk-0.1.7-py3-none-any.whl\n",
      "Collecting nbconvert<=6.0.7\n",
      "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting keras<=2.4.3\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting psutil<=5.7.3\n",
      "  Using cached psutil-5.7.3-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting numpy<=1.19.3\n",
      "  Using cached numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Collecting py-cpuinfo<=7.0.0\n",
      "  Using cached py_cpuinfo-7.0.0-py3-none-any.whl\n",
      "Collecting nbformat<=5.0.8\n",
      "  Using cached nbformat-5.0.8-py3-none-any.whl (172 kB)\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640 kB)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
      "Collecting scipy>=0.14\n",
      "  Using cached scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting jupyter-core\n",
      "  Using cached jupyter_core-4.7.1-py3-none-any.whl (82 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.4.3-py3-none-any.whl\n",
      "Collecting traitlets>=4.2\n",
      "  Using cached traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-3.3.0-py2.py3-none-any.whl (283 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Using cached nbclient-0.5.3-py3-none-any.whl (82 kB)\n",
      "Collecting testpath\n",
      "  Using cached testpath-0.5.0-py3-none-any.whl (84 kB)\n",
      "Collecting jinja2>=2.4\n",
      "  Using cached Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
      "Collecting pygments>=2.4.1\n",
      "  Using cached Pygments-2.9.0-py3-none-any.whl (1.0 MB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting async-generator\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting nest-asyncio\n",
      "  Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB)\n",
      "Collecting jupyter-client>=6.1.5\n",
      "  Using cached jupyter_client-6.1.12-py3-none-any.whl (112 kB)\n",
      "Collecting tornado>=4.1\n",
      "  Using cached tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pyzmq>=13\n",
      "  Using cached pyzmq-22.0.3-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting ipython-genutils\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting six>=1.11.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-56.2.0-py3-none-any.whl (785 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Using cached pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting attrs>=17.4.0\n",
      "  Using cached attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting decorator\n",
      "  Using cached decorator-5.0.9-py3-none-any.whl (8.9 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cached-property\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Installing collected packages: zipp, typing-extensions, six, ipython-genutils, decorator, traitlets, setuptools, pyrsistent, importlib-metadata, attrs, tornado, pyzmq, python-dateutil, pyparsing, jupyter-core, jsonschema, webencodings, pygments, packaging, numpy, nest-asyncio, nbformat, MarkupSafe, jupyter-client, cached-property, async-generator, testpath, scipy, pyyaml, pandocfilters, nbclient, mistune, jupyterlab-pygments, jinja2, h5py, entrypoints, defusedxml, bleach, py-cpuinfo, psutil, nbconvert, keras, ait-sdk\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.1\n",
      "    Uninstalling zipp-3.4.1:\n",
      "      Successfully uninstalled zipp-3.4.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Attempting uninstall: ipython-genutils\n",
      "    Found existing installation: ipython-genutils 0.2.0\n",
      "    Uninstalling ipython-genutils-0.2.0:\n",
      "      Successfully uninstalled ipython-genutils-0.2.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.1.2\n",
      "    Uninstalling decorator-4.1.2:\n",
      "      Successfully uninstalled decorator-4.1.2\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 4.3.3\n",
      "    Uninstalling traitlets-4.3.3:\n",
      "      Successfully uninstalled traitlets-4.3.3\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 56.2.0\n",
      "    Uninstalling setuptools-56.2.0:\n",
      "      Successfully uninstalled setuptools-56.2.0\n",
      "  Attempting uninstall: pyrsistent\n",
      "    Found existing installation: pyrsistent 0.17.3\n",
      "    Uninstalling pyrsistent-0.17.3:\n",
      "      Successfully uninstalled pyrsistent-0.17.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.2.0\n",
      "    Uninstalling attrs-21.2.0:\n",
      "      Successfully uninstalled attrs-21.2.0\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.1\n",
      "    Uninstalling tornado-6.1:\n",
      "      Successfully uninstalled tornado-6.1\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 22.0.3\n",
      "    Uninstalling pyzmq-22.0.3:\n",
      "      Successfully uninstalled pyzmq-22.0.3\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.6.1\n",
      "    Uninstalling python-dateutil-2.6.1:\n",
      "      Successfully uninstalled python-dateutil-2.6.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.2.0\n",
      "    Uninstalling pyparsing-2.2.0:\n",
      "      Successfully uninstalled pyparsing-2.2.0\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.7.1\n",
      "    Uninstalling jupyter-core-4.7.1:\n",
      "      Successfully uninstalled jupyter-core-4.7.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 3.2.0\n",
      "    Uninstalling jsonschema-3.2.0:\n",
      "      Successfully uninstalled jsonschema-3.2.0\n",
      "  Attempting uninstall: webencodings\n",
      "    Found existing installation: webencodings 0.5.1\n",
      "    Uninstalling webencodings-0.5.1:\n",
      "      Successfully uninstalled webencodings-0.5.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.9.0\n",
      "    Uninstalling Pygments-2.9.0:\n",
      "      Successfully uninstalled Pygments-2.9.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.1\n",
      "    Uninstalling nest-asyncio-1.5.1:\n",
      "      Successfully uninstalled nest-asyncio-1.5.1\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.0.8\n",
      "    Uninstalling nbformat-5.0.8:\n",
      "      Successfully uninstalled nbformat-5.0.8\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 6.1.12\n",
      "    Uninstalling jupyter-client-6.1.12:\n",
      "      Successfully uninstalled jupyter-client-6.1.12\n",
      "  Attempting uninstall: cached-property\n",
      "    Found existing installation: cached-property 1.5.2\n",
      "    Uninstalling cached-property-1.5.2:\n",
      "      Successfully uninstalled cached-property-1.5.2\n",
      "  Attempting uninstall: async-generator\n",
      "    Found existing installation: async-generator 1.10\n",
      "    Uninstalling async-generator-1.10:\n",
      "      Successfully uninstalled async-generator-1.10\n",
      "  Attempting uninstall: testpath\n",
      "    Found existing installation: testpath 0.5.0\n",
      "    Uninstalling testpath-0.5.0:\n",
      "      Successfully uninstalled testpath-0.5.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 0.19.1\n",
      "    Uninstalling scipy-0.19.1:\n",
      "      Successfully uninstalled scipy-0.19.1\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.12\n",
      "    Uninstalling PyYAML-3.12:\n",
      "      Successfully uninstalled PyYAML-3.12\n",
      "  Attempting uninstall: pandocfilters\n",
      "    Found existing installation: pandocfilters 1.4.3\n",
      "    Uninstalling pandocfilters-1.4.3:\n",
      "      Successfully uninstalled pandocfilters-1.4.3\n",
      "  Attempting uninstall: nbclient\n",
      "    Found existing installation: nbclient 0.5.3\n",
      "    Uninstalling nbclient-0.5.3:\n",
      "      Successfully uninstalled nbclient-0.5.3\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: jupyterlab-pygments\n",
      "    Found existing installation: jupyterlab-pygments 0.1.2\n",
      "    Uninstalling jupyterlab-pygments-0.1.2:\n",
      "      Successfully uninstalled jupyterlab-pygments-0.1.2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.0.1\n",
      "    Uninstalling Jinja2-3.0.1:\n",
      "      Successfully uninstalled Jinja2-3.0.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.9.0\n",
      "    Uninstalling h5py-2.9.0:\n",
      "      Successfully uninstalled h5py-2.9.0\n",
      "  Attempting uninstall: entrypoints\n",
      "    Found existing installation: entrypoints 0.3\n",
      "    Uninstalling entrypoints-0.3:\n",
      "      Successfully uninstalled entrypoints-0.3\n",
      "  Attempting uninstall: defusedxml\n",
      "    Found existing installation: defusedxml 0.7.1\n",
      "    Uninstalling defusedxml-0.7.1:\n",
      "      Successfully uninstalled defusedxml-0.7.1\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 1.5.0\n",
      "    Uninstalling bleach-1.5.0:\n",
      "      Successfully uninstalled bleach-1.5.0\n",
      "  Attempting uninstall: py-cpuinfo\n",
      "    Found existing installation: py-cpuinfo 7.0.0\n",
      "    Uninstalling py-cpuinfo-7.0.0:\n",
      "      Successfully uninstalled py-cpuinfo-7.0.0\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.7.3\n",
      "    Uninstalling psutil-5.7.3:\n",
      "      Successfully uninstalled psutil-5.7.3\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.0.7\n",
      "    Uninstalling nbconvert-6.0.7:\n",
      "      Successfully uninstalled nbconvert-6.0.7\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.0.8\n",
      "    Uninstalling Keras-2.0.8:\n",
      "      Successfully uninstalled Keras-2.0.8\n",
      "  Attempting uninstall: ait-sdk\n",
      "    Found existing installation: ait-sdk 0.1.7\n",
      "    Uninstalling ait-sdk-0.1.7:\n",
      "      Successfully uninstalled ait-sdk-0.1.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-tensorboard 0.1.6 requires bleach==1.5.0, but you have bleach 3.3.0 which is incompatible.\u001b[0m\n",
      "Successfully installed MarkupSafe-2.0.1 ait-sdk-0.1.7 async-generator-1.10 attrs-21.2.0 bleach-3.3.0 cached-property-1.5.2 decorator-5.0.9 defusedxml-0.7.1 entrypoints-0.3 h5py-3.1.0 importlib-metadata-4.0.1 ipython-genutils-0.2.0 jinja2-3.0.1 jsonschema-3.2.0 jupyter-client-6.1.12 jupyter-core-4.7.1 jupyterlab-pygments-0.1.2 keras-2.4.3 mistune-0.8.4 nbclient-0.5.3 nbconvert-6.0.7 nbformat-5.0.8 nest-asyncio-1.5.1 numpy-1.19.3 packaging-20.9 pandocfilters-1.4.3 psutil-5.7.3 py-cpuinfo-7.0.0 pygments-2.9.0 pyparsing-2.4.7 pyrsistent-0.17.3 python-dateutil-2.8.1 pyyaml-5.4.1 pyzmq-22.0.3 scipy-1.5.4 setuptools-56.2.0 six-1.16.0 testpath-0.5.0 tornado-6.1 traitlets-4.3.3 typing-extensions-3.10.0.0 webencodings-0.5.1 zipp-3.4.1\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:ait-sdk install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    # get ait-sdk file name\n",
    "    from pathlib import Path\n",
    "    from glob import glob\n",
    "    import re\n",
    "\n",
    "    def numericalSort(value):\n",
    "        numbers = re.compile(r'(\\d+)')\n",
    "        parts = numbers.split(value)\n",
    "        parts[1::2] = map(int, parts[1::2])\n",
    "        return parts\n",
    "    latest_sdk_file_path=sorted(glob('../lib/*.whl'), key=numericalSort)[-1]\n",
    "\n",
    "    ait_sdk_name = Path(latest_sdk_file_path).name\n",
    "    \n",
    "    # copy to develop dir\n",
    "    import shutil\n",
    "    current_dir = %pwd\n",
    "    shutil.copyfile(f'../lib/{ait_sdk_name}', f'{current_dir}/{ait_sdk_name}')\n",
    "\n",
    "    # install ait-sdk\n",
    "    !pip install --upgrade pip\n",
    "    !pip install --force-reinstall ./$ait_sdk_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_requirements_generator import AITRequirementsGenerator\n",
    "    requirements_generator = AITRequirementsGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package('Cython', '0.29.21')\n",
    "    requirements_generator.add_package('bleach','1.5.0')\n",
    "    requirements_generator.add_package('cycler','0.10.0')\n",
    "    requirements_generator.add_package('decorator','4.1.2')\n",
    "    requirements_generator.add_package('h5py','2.9.0')\n",
    "    requirements_generator.add_package('html5lib','0.9999999')\n",
    "    requirements_generator.add_package('Keras','2.0.8')\n",
    "    requirements_generator.add_package('Markdown','2.6.9')\n",
    "    requirements_generator.add_package('matplotlib','2.0.2')\n",
    "    requirements_generator.add_package('networkx','1.11')\n",
    "    requirements_generator.add_package('numpy','1.19.2')\n",
    "    requirements_generator.add_package('olefile','0.44')\n",
    "    requirements_generator.add_package('pandas','0.20.3')\n",
    "    requirements_generator.add_package('Pillow','4.3.0')\n",
    "    requirements_generator.add_package('protobuf','3.6.1')\n",
    "    requirements_generator.add_package('pyparsing','2.2.0')\n",
    "    requirements_generator.add_package('python-dateutil','2.6.1')\n",
    "    requirements_generator.add_package('pytz','2017.2')\n",
    "    requirements_generator.add_package('PyWavelets','1.1.1')\n",
    "    requirements_generator.add_package('PyYAML','3.12')\n",
    "    requirements_generator.add_package('scikit-image','0.14.2')\n",
    "    requirements_generator.add_package('scikit-learn','0.19.0')\n",
    "    requirements_generator.add_package('scipy','0.19.1')\n",
    "    requirements_generator.add_package('six','1.11.0')\n",
    "    requirements_generator.add_package('tensorflow','1.13.1')\n",
    "    requirements_generator.add_package('tensorflow-tensorboard','0.1.6')\n",
    "    requirements_generator.add_package('Werkzeug','0.12.2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./ait_sdk-0.1.7-py3-none-any.whl\n",
      "Requirement already satisfied: Cython==0.29.21 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 1)) (0.29.21)\n",
      "Collecting bleach==1.5.0\n",
      "  Using cached bleach-1.5.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 3)) (0.10.0)\n",
      "Collecting decorator==4.1.2\n",
      "  Using cached decorator-4.1.2-py2.py3-none-any.whl (9.1 kB)\n",
      "Collecting h5py==2.9.0\n",
      "  Using cached h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8 MB)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 6)) (0.9999999)\n",
      "Collecting Keras==2.0.8\n",
      "  Using cached Keras-2.0.8-py2.py3-none-any.whl (276 kB)\n",
      "Requirement already satisfied: Markdown==2.6.9 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 8)) (2.6.9)\n",
      "Requirement already satisfied: matplotlib==2.0.2 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 9)) (2.0.2)\n",
      "Requirement already satisfied: networkx==1.11 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 10)) (1.11)\n",
      "Collecting numpy==1.19.2\n",
      "  Using cached numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Requirement already satisfied: olefile==0.44 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 12)) (0.44)\n",
      "Requirement already satisfied: pandas==0.20.3 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 13)) (0.20.3)\n",
      "Requirement already satisfied: Pillow==4.3.0 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 14)) (4.3.0)\n",
      "Requirement already satisfied: protobuf==3.6.1 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 15)) (3.6.1)\n",
      "Collecting pyparsing==2.2.0\n",
      "  Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting python-dateutil==2.6.1\n",
      "  Using cached python_dateutil-2.6.1-py2.py3-none-any.whl (194 kB)\n",
      "Requirement already satisfied: pytz==2017.2 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 18)) (2017.2)\n",
      "Requirement already satisfied: PyWavelets==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 19)) (1.1.1)\n",
      "Collecting PyYAML==3.12\n",
      "  Using cached PyYAML-3.12-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: scikit-image==0.14.2 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 21)) (0.14.2)\n",
      "Requirement already satisfied: scikit-learn==0.19.0 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 22)) (0.19.0)\n",
      "Collecting scipy==0.19.1\n",
      "  Using cached scipy-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (48.2 MB)\n",
      "Collecting six==1.11.0\n",
      "  Using cached six-1.11.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 25)) (1.13.1)\n",
      "Requirement already satisfied: tensorflow-tensorboard==0.1.6 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 26)) (0.1.6)\n",
      "Requirement already satisfied: Werkzeug==0.12.2 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 27)) (0.12.2)\n",
      "Requirement already satisfied: nbconvert<=6.0.7 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (6.0.7)\n",
      "Requirement already satisfied: psutil<=5.7.3 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (5.7.3)\n",
      "Requirement already satisfied: py-cpuinfo<=7.0.0 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (7.0.0)\n",
      "Requirement already satisfied: nbformat<=5.0.8 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (5.0.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf==3.6.1->-r /workdir/root/develop/requirements.txt (line 15)) (56.2.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.2->-r /workdir/root/develop/requirements.txt (line 21)) (1.6.0)\n",
      "Requirement already satisfied: dask[array]>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.2->-r /workdir/root/develop/requirements.txt (line 21)) (2021.3.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (1.13.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (1.34.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (0.30.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (1.0.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (0.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (1.13.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.6/dist-packages (from dask[array]>=1.0.0->scikit-image==0.14.2->-r /workdir/root/develop/requirements.txt (line 21)) (0.11.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (4.3.3)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (1.4.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (0.3)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (3.0.1)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (4.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (0.5.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (0.8.4)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (2.9.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (0.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (2.0.1)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (1.10)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (6.1.12)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (1.5.1)\n",
      "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (6.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (22.0.3)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat<=5.0.8->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat<=5.0.8->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (3.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (4.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (0.17.3)\n",
      "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->-r /workdir/root/develop/requirements.txt (line 25)) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.7->-r /workdir/root/develop/requirements.txt (line 28)) (3.4.1)\n",
      "ait-sdk is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Installing collected packages: six, decorator, python-dateutil, PyYAML, numpy, scipy, pyparsing, h5py, bleach, Keras\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.0.9\n",
      "    Uninstalling decorator-5.0.9:\n",
      "      Successfully uninstalled decorator-5.0.9\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.3\n",
      "    Uninstalling numpy-1.19.3:\n",
      "      Successfully uninstalled numpy-1.19.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 3.3.0\n",
      "    Uninstalling bleach-3.3.0:\n",
      "      Successfully uninstalled bleach-3.3.0\n",
      "  Attempting uninstall: Keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed Keras-2.0.8 PyYAML-3.12 bleach-1.5.0 decorator-4.1.2 h5py-2.9.0 numpy-1.19.2 pyparsing-2.2.0 python-dateutil-2.6.1 scipy-0.19.1 six-1.11.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package(f'./{ait_sdk_name}')\n",
    "    requirements_path = requirements_generator.create_requirements(current_dir)\n",
    "\n",
    "    !pip install -r $requirements_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:import\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "# import if you need modules cell\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from os import makedirs, path\n",
    "from glob import glob\n",
    "import csv\n",
    "from deep_saucer.neuron_coverage.tensorflow_native.lib.coverage_verification import main_test\n",
    "from ait_sdk.utils.mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:import\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "# must use modules\n",
    "import shutil  # do not remove\n",
    "from ait_sdk.common.files.ait_input import AITInput  # do not remove\n",
    "from ait_sdk.common.files.ait_output import AITOutput  # do not remove\n",
    "from ait_sdk.common.files.ait_manifest import AITManifest  # do not remove\n",
    "from ait_sdk.develop.ait_path_helper import AITPathHelper  # do not remove\n",
    "from ait_sdk.utils.logging import get_logger, log, get_log_path  # do not remove\n",
    "from ait_sdk.develop.annotation import measures, resources, downloads, ait_main  # do not remove\n",
    "# must use modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create manifest\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_manifest_generator import AITManifestGenerator\n",
    "    \n",
    "    manifest_genenerator = AITManifestGenerator(current_dir)\n",
    "    manifest_genenerator.set_ait_name('eval_dnn_coverage_tf1.13')\n",
    "    manifest_genenerator.set_ait_description('''\n",
    "    Calculate the neuron coverage for the input dataset given by the user, and display it in the form of a heat map. After that, a gradient for the input dataset is computed by backpropagation. Based on the gradient, the most efficient manipulation to input values in order for the neuron coverage to increase is selected. A number of data is removed from the dataset, and these removed data are converted to new data by the selected manipulation. Then, the new data is added to the dataset, and the coverage is recalculated by running the model with the updated dataset. Similarly, a gradient for the updated dataset is computed. These processes are repeated until the target coverage rate is achieved. Data manipulation algorithm is implemented by the user in Python.\n",
    "    ''')\n",
    "    manifest_genenerator.set_ait_author('AIST')\n",
    "    manifest_genenerator.set_ait_email('')\n",
    "    manifest_genenerator.set_ait_version('0.1')\n",
    "    manifest_genenerator.set_ait_quality('https://airc.aist.go.jp/aiqm/quality/internal/Robustness_of_trained_model')\n",
    "    manifest_genenerator.set_ait_reference('')\n",
    "    manifest_genenerator.add_ait_inventories(name='image_data', \n",
    "                                             type_='dataset', \n",
    "                                             description='MNIST image data', \n",
    "                                             format_=['gz'], \n",
    "                                             schema='http://yann.lecun.com/exdb/mnist/')\n",
    "    manifest_genenerator.add_ait_inventories(name='label', \n",
    "                                             type_='dataset', \n",
    "                                             description='MNIST label data', \n",
    "                                             format_=['gz'], \n",
    "                                             schema='http://yann.lecun.com/exdb/mnist/')\n",
    "    manifest_genenerator.add_ait_inventories(name='tf_ckpt', \n",
    "                                             type_='model', \n",
    "                                             description='''Tensorflow model datas.\\n\n",
    "                                             This is loaded by `tf.train.import_meta_graph`.''', \n",
    "                                             format_=['*'], \n",
    "                                             schema='https://github.com/tensorflow/models/tree/master/official')\n",
    "    manifest_genenerator.add_ait_parameters(name='determination_on_activation', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Neuron Activity/Inactivity\\n\n",
    "                                            Determination Type\\n\n",
    "                                            0: Threshold Determination\\n\n",
    "                                            1: Upper/Lower Limit Determination\\n\n",
    "                                            2: N Cases of Maximum Value Determination\n",
    "                                            ''', \n",
    "                                            default_val='0',\n",
    "                                            min_value='0',\n",
    "                                            max_value='2')\n",
    "    manifest_genenerator.add_ait_parameters(name='threshold', \n",
    "                                            type_='float', \n",
    "                                            description='''\n",
    "                                            Threshold\\n\n",
    "                                            Valid only for threshold determination\n",
    "                                            ''', \n",
    "                                            default_val='0',\n",
    "                                            min_value='0',\n",
    "                                            max_value='1')\n",
    "    manifest_genenerator.add_ait_parameters(name='lower_bound', \n",
    "                                            type_='float', \n",
    "                                            description='''\n",
    "                                            Lower Limit\\n\n",
    "                                            No default value\\n\n",
    "                                            (Valid only for upper/lower limit determination)\n",
    "                                            ''')\n",
    "    manifest_genenerator.add_ait_parameters(name='upper_bound', \n",
    "                                            type_='float', \n",
    "                                            description='''\n",
    "                                            Upper Limit\\n\n",
    "                                            No default value\\n\n",
    "                                            (Valid only for upper/lower limit determination\n",
    "                                            ''')\n",
    "    manifest_genenerator.add_ait_parameters(name='activation_filter_no', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Number of Cases N\\n\n",
    "                                            The default value is 1\\n\n",
    "                                            (Valid only for N Cases of maximum value determination)\n",
    "                                            ''', \n",
    "                                            default_val='1',\n",
    "                                            min_value='0')\n",
    "    manifest_genenerator.add_ait_parameters(name='heat_map_type', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Heat Map Generation Method Type\\n\n",
    "                                            The default value is 1\\n\n",
    "                                            0: Generation Not Necessary\\n\n",
    "                                            1: 0/1 Table\\n\n",
    "                                            2: Simple Increment\\n\n",
    "                                            3: Density Coverage\\n\n",
    "                                            ''', \n",
    "                                            default_val='1',\n",
    "                                            min_value='0',\n",
    "                                            max_value='3')\n",
    "    manifest_genenerator.add_ait_parameters(name='combination_type', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Combination Type\\n\n",
    "                                            The default value is 0\\n\n",
    "                                            0: Implementation Not Necessary\\n\n",
    "                                            1: Execute\n",
    "                                            ''', \n",
    "                                            default_val='0',\n",
    "                                            min_value='0',\n",
    "                                            max_value='1')\n",
    "    manifest_genenerator.add_ait_parameters(name='combination_first', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            One Layer of Combination Coverage Target\\n\n",
    "                                            No default value\\n\n",
    "                                            (Valid and mandatory only for combination type execution)\n",
    "                                            ''')\n",
    "    manifest_genenerator.add_ait_parameters(name='combination_second', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            The Other Layer of Combination Coverage Target\\n\n",
    "                                            No default value\\n\n",
    "                                            (Valid and mandatory only for combination type execution)\n",
    "                                            ''')\n",
    "    manifest_genenerator.add_ait_parameters(name='target_scope_name', \n",
    "                                            type_='list[str]', \n",
    "                                            description='''\n",
    "                                            Names of tensorflow scopes in which neural networks are defined\\n\n",
    "                                            No default value (Mandatory)\\n\n",
    "                                            List items are separate by \",\".\n",
    "                                            ''')\n",
    "    manifest_genenerator.add_ait_parameters(name='edit_num', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Number of data manipulated at a time\\n\n",
    "                                            The default value is 100\n",
    "                                            ''', \n",
    "                                            default_val='100',\n",
    "                                            min_value='1')\n",
    "    manifest_genenerator.add_ait_parameters(name='target_rate', \n",
    "                                            type_='float', \n",
    "                                            description='''\n",
    "                                            Target Coverage Rate (Execution terminates when the coverage reaches Target Coverage Rate)\\n\n",
    "                                            The default value is 1.0\n",
    "                                            ''', \n",
    "                                            default_val='1.0',\n",
    "                                            min_value='0',\n",
    "                                            max_value='1.0')\n",
    "    manifest_genenerator.add_ait_parameters(name='increase_rate', \n",
    "                                            type_='float', \n",
    "                                            description='''\n",
    "                                            Expected Coverage Growth Rate (if the coverage growth rage compared to 5 times before is less than Expected Coverage Growth Rate, unused manipulations are preferentially selected)\\n\n",
    "                                            The default value is 0.0\n",
    "                                            ''', \n",
    "                                            default_val='0',\n",
    "                                            max_value='0')\n",
    "    manifest_genenerator.add_ait_parameters(name='dataset_x_num', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Number of Input Data Placeholders (in the given dataset)\\n\n",
    "                                            No default value (Mandatory)\n",
    "                                            ''',\n",
    "                                            min_value='1')\n",
    "    manifest_genenerator.add_ait_parameters(name='dataset_y_num', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Number of Label Data Placeholders (in the given dataset)\\n\n",
    "                                            No default value (Mandatory)\n",
    "                                            ''',\n",
    "                                            min_value='1')\n",
    "    manifest_genenerator.add_ait_parameters(name='dataset_k_num', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Number of Constant Data Placeholders (in the given dataset)\\n\n",
    "                                            No default value (Mandatory)\n",
    "                                            ''',\n",
    "                                            min_value='1')\n",
    "    manifest_genenerator.add_ait_parameters(name='split_dataset_start', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Dataset Division Start Position (Data from Start Position to End Position of the given dataset are used for coverage testing)\\n\n",
    "                                            The default value is 0\n",
    "                                            ''', \n",
    "                                            default_val='0',\n",
    "                                            min_value='0')\n",
    "    manifest_genenerator.add_ait_parameters(name='split_dataset_end', \n",
    "                                            type_='int', \n",
    "                                            description='''\n",
    "                                            Dataset Division End Position (Data from Start Position to End Position of the given dataset are used for coverage testing)\\n\n",
    "                                            The default value is the size of the given dataset\n",
    "                                            ''', \n",
    "                                            default_val='100',\n",
    "                                            min_value='1')\n",
    "    manifest_genenerator.add_ait_parameters(name='implement_class_name', \n",
    "                                            type_='str', \n",
    "                                            description='''\n",
    "                                            Class Name in which function 'get_atomic_manipulations' is implemented\\n\n",
    "                                            No default value (Mandatory)\n",
    "                                            ''')\n",
    "    manifest_genenerator.add_ait_measures(name='coverage_rate_all_layer', \n",
    "                                          type_='float', \n",
    "                                          description='coverage of the model as a whole.', \n",
    "                                          structure='single',\n",
    "                                          min='0',\n",
    "                                          max='1')\n",
    "    manifest_genenerator.add_ait_measures(name='coverage_rate_each_layer', \n",
    "                                          type_='float', \n",
    "                                          description='coverage of each layer in the model.', \n",
    "                                          structure='sequence',\n",
    "                                          min='0',\n",
    "                                          max='1')\n",
    "    manifest_genenerator.add_ait_measures(name='coverage_rate_combination', \n",
    "                                          type_='float', \n",
    "                                          description='coverage of select combination.', \n",
    "                                          structure='single',\n",
    "                                          min='0',\n",
    "                                          max='1')\n",
    "    manifest_genenerator.add_ait_resources(name='test_case_generator',  \n",
    "                                           type_='table', \n",
    "                                           description='generate coverage increase data.')\n",
    "    manifest_genenerator.add_ait_downloads(name='heatmap', \n",
    "                                           description='the heat map of the coverage as an HTML file.')\n",
    "    manifest_genenerator.add_ait_downloads(name='abs_dataset', \n",
    "                                           description='the created input data by the manipulation as h5 file.')\n",
    "    manifest_genenerator.add_ait_downloads(name='Log', \n",
    "                                           description='AITLog')\n",
    "    manifest_path = manifest_genenerator.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create input\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_input_generator import AITInputGenerator\n",
    "    input_generator = AITInputGenerator(manifest_path)\n",
    "    input_generator.add_ait_inventories(name='image_data',\n",
    "                                        value='MNIST_data/image/train-images-idx3-ubyte.gz')\n",
    "    input_generator.add_ait_inventories(name='label',\n",
    "                                        value='MNIST_data/label/train-labels-idx1-ubyte.gz')\n",
    "    input_generator.add_ait_inventories(name='tf_ckpt',\n",
    "                                        value='tf_ckpt')\n",
    "    input_generator.set_ait_params(name='determination_on_activation',\n",
    "                                   value='0')\n",
    "    input_generator.set_ait_params(name='threshold',\n",
    "                                   value='0.5')\n",
    "    input_generator.set_ait_params(name='lower_bound',\n",
    "                                   value='0.5')\n",
    "    input_generator.set_ait_params(name='upper_bound',\n",
    "                                   value='1')\n",
    "    input_generator.set_ait_params(name='activation_filter_no',\n",
    "                                   value='10')\n",
    "    input_generator.set_ait_params(name='heat_map_type',\n",
    "                                   value='1')\n",
    "    input_generator.set_ait_params(name='combination_type',\n",
    "                                   value='1')\n",
    "    input_generator.set_ait_params(name='combination_first',\n",
    "                                   value='4')\n",
    "    input_generator.set_ait_params(name='combination_second',\n",
    "                                   value='5')\n",
    "    input_generator.set_ait_params(name='target_scope_name',\n",
    "                                   value='conv1,conv2,conv3,conv4,conv5,conv6,fc1')\n",
    "    input_generator.set_ait_params(name='edit_num',\n",
    "                                   value='10')\n",
    "    input_generator.set_ait_params(name='target_rate',\n",
    "                                   value='1.0')\n",
    "    input_generator.set_ait_params(name='increase_rate',\n",
    "                                   value='0.0')\n",
    "    input_generator.set_ait_params(name='dataset_x_num',\n",
    "                                   value='1')\n",
    "    input_generator.set_ait_params(name='dataset_y_num',\n",
    "                                   value='1')\n",
    "    input_generator.set_ait_params(name='dataset_k_num',\n",
    "                                   value='1')\n",
    "    input_generator.set_ait_params(name='split_dataset_start',\n",
    "                                   value='0')\n",
    "    input_generator.set_ait_params(name='split_dataset_end',\n",
    "                                   value='100')\n",
    "    input_generator.set_ait_params(name='implement_class_name',\n",
    "                                   value='Tutorial')\n",
    "    input_generator.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:initialize\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "ait_manifest = AITManifest()\n",
    "ait_input = AITInput(ait_manifest)\n",
    "ait_output = AITOutput(ait_manifest)\n",
    "\n",
    "if is_ait_launch:\n",
    "    # launch from AIT\n",
    "    current_dir = path.dirname(path.abspath(__file__))\n",
    "    path_helper = AITPathHelper(argv=sys.argv, ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "else:\n",
    "    # launch from jupyter notebook\n",
    "    # ait.input.json make in input_dir\n",
    "    input_dir = '/usr/local/qai/mnt/ip/job_args/1/1'\n",
    "    current_dir = %pwd\n",
    "    path_helper = AITPathHelper(argv=['', input_dir], ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "\n",
    "ait_input.read_json(path_helper.get_input_file_path())\n",
    "ait_manifest.read_json(path_helper.get_manifest_file_path())\n",
    "\n",
    "### do not edit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_list(list_dict):\n",
    "    return [float(list(l.values())[0]) for l in list_dict]\n",
    "\n",
    "def add_config_json(name, ait_input, config_json) -> None:\n",
    "    value = ait_input.get_method_param_value(name)\n",
    "    config_json[name] = value\n",
    "\n",
    "def create_config_json(ait_input):\n",
    "    config_json = {}\n",
    "\n",
    "    add_config_json('determination_on_activation', ait_input, config_json)\n",
    "    add_config_json('threshold', ait_input, config_json)\n",
    "    add_config_json('lower_bound', ait_input, config_json)\n",
    "    add_config_json('upper_bound', ait_input, config_json)\n",
    "    add_config_json('heat_map_type', ait_input, config_json)\n",
    "    add_config_json('activation_filter_no', ait_input, config_json)\n",
    "    add_config_json('combination_type', ait_input, config_json)\n",
    "    add_config_json('combination_first', ait_input, config_json)\n",
    "    add_config_json('combination_second', ait_input, config_json)\n",
    "    add_config_json('target_scope_name', ait_input, config_json)\n",
    "    add_config_json('edit_num', ait_input, config_json)\n",
    "    add_config_json('target_rate', ait_input, config_json)\n",
    "    add_config_json('increase_rate', ait_input, config_json)\n",
    "    config_json['output_file_name'] = 'examples/output.h5'\n",
    "    config_json['network_structure_path'] = 'examples/tf_ckpt/model.ckpt_name.json'\n",
    "    add_config_json('dataset_x_num', ait_input, config_json)\n",
    "    add_config_json('dataset_y_num', ait_input, config_json)\n",
    "    add_config_json('dataset_k_num', ait_input, config_json)\n",
    "    add_config_json('split_dataset_start', ait_input, config_json)\n",
    "    add_config_json('split_dataset_end', ait_input, config_json)\n",
    "    add_config_json('implement_class_name', ait_input, config_json)\n",
    "    \n",
    "    return config_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'coverage_rate_all_layer')\n",
    "def calc_coverage_rate_all_layer(coverage_rate):\n",
    "    return np.mean(get_value_list(coverage_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'coverage_rate_each_layer', is_many=True)\n",
    "def calc_coverage_rate_each_layer(coverage_rate):\n",
    "    return get_value_list(coverage_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'coverage_rate_combination')\n",
    "def calc_coverage_rate_combination(combination_cov):\n",
    "    return list(combination_cov.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'heatmap', 'heatmap.html')\n",
    "def save_heatmap(result_heatmap_output, file_path: str=None) -> None:\n",
    "    shutil.copyfile(result_heatmap_output, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@resources(ait_output, path_helper, 'test_case_generator', 'test_case_generator.csv')\n",
    "def save_test_case_generator(result_test_case_generator, file_path: str=None) -> None:\n",
    "    with open(file_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(result_test_case_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'Log', 'ait.log')\n",
    "def move_log(file_path: str=None) -> None:\n",
    "    shutil.move(get_log_path(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'abs_dataset', 'output.h5')\n",
    "def save_abs_dataset(result_abs_dataset_pass, file_path: str=None) -> None:\n",
    "    shutil.copyfile(result_abs_dataset_pass, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:main\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@ait_main(ait_output, path_helper)\n",
    "def main() -> None:\n",
    "\n",
    "    image_px_size = 28\n",
    "    \n",
    "    mnist = MNIST()\n",
    "    X_test = mnist.load_image(ait_input.get_inventory_path('image_data'), image_px_size)\n",
    "    y_test = mnist.load_label(ait_input.get_inventory_path('label'))\n",
    "    \n",
    "    # reshape for dnn coverage\n",
    "    X_test = X_test.reshape([X_test.shape[0], image_px_size*image_px_size])\n",
    "    \n",
    "    # onehot for dnn coverage\n",
    "    class_num = len(np.unique(y_test))\n",
    "    y_test = np.identity(class_num)[y_test]\n",
    "    \n",
    "    data_set = [\n",
    "        # x_input\n",
    "        X_test,\n",
    "        # y_input\n",
    "        y_test,\n",
    "        # k_input\n",
    "        1.0\n",
    "    ]\n",
    "    \n",
    "    session = tf.Session()\n",
    "\n",
    "    tf_ckpt_path = ait_input.get_inventory_path('tf_ckpt')\n",
    "    model_meta_path = glob(f'{tf_ckpt_path}/*.meta')[0]\n",
    "    model_path = '{}/{}'.format(tf_ckpt_path, str(Path(model_meta_path).stem))\n",
    "    \n",
    "    saver = tf.train.import_meta_graph(model_meta_path)\n",
    "    saver.restore(session, str(model_path))\n",
    "\n",
    "    conf_json = create_config_json(ait_input)\n",
    "    \n",
    "    # run coverage verification\n",
    "    result_coverage_rate, result_heatmap_output, result_combination_cov_output, result_test_case_generator, result_abs_dataset_pass = \\\n",
    "        main_test(session, data_set, conf_json)\n",
    "    \n",
    "    calc_coverage_rate_all_layer(result_coverage_rate)\n",
    "    calc_coverage_rate_each_layer(result_coverage_rate)\n",
    "    calc_coverage_rate_combination(result_combination_cov_output)\n",
    "    \n",
    "    save_test_case_generator(result_test_case_generator)\n",
    "    \n",
    "    save_heatmap(result_heatmap_output)\n",
    "    save_abs_dataset(result_abs_dataset_pass)\n",
    "    move_log()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage rate all layer :  0.6704282407407407\n",
      "Coverage rate one layer conv1:  1.0\n",
      "Coverage rate one layer conv2:  0.49107142857142855\n",
      "Coverage rate one layer conv3:  0.4252232142857143\n",
      "Coverage rate one layer conv4:  0.5462372448979592\n",
      "Coverage rate one layer conv5:  0.6693239795918368\n",
      "Coverage rate one layer conv6:  0.7834821428571429\n",
      "Coverage rate one layer fc1:  0.75\n",
      "Multiple layers combination coverage rate 4 and 5: 0.40959658735943355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage rate sum layer : 0.672075\n",
      "Coverage rate sum layer : 0.672298\n",
      "Coverage rate sum layer : 0.672431\n",
      "Coverage rate sum layer : 0.672565\n",
      "Coverage rate sum layer : 0.672632\n",
      "Coverage rate sum layer : 0.672721\n",
      "Coverage rate sum layer : 0.67301\n",
      "Coverage rate sum layer : 0.673032\n",
      "Coverage rate sum layer : 0.673277\n",
      "Coverage rate sum layer : 0.6733\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:entory point\n",
    "# do not edit\n",
    "#########################################\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:license attribute set\n",
    "# should edit\n",
    "#########################################\n",
    "ait_owner='AIST'\n",
    "ait_creation_year='2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:prepare deproy\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.deploy import prepare_deploy\n",
    "    from ait_sdk.license.license_generator import LicenseGenerator\n",
    "    \n",
    "    current_dir = %pwd\n",
    "    prepare_deploy(ait_manifest, ait_sdk_name, current_dir, requirements_path, is_remote_deploy=True)\n",
    "    \n",
    "    # output License.txt\n",
    "    license_generator = LicenseGenerator()\n",
    "    license_generator.write('../top_dir/LICENSE.txt', ait_creation_year, ait_owner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
