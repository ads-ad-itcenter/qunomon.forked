{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# AIT Development notebook\n",
    "\n",
    "\n",
    "## notebook of structure\n",
    "\n",
    "|#|area name|cell num|description|edit or not|\n",
    "|---|---|---|---|---|\n",
    "| 1|flags set|1|setting of launch jupyter or ait flag.|no edit|\n",
    "| 2|ait-sdk install|1|Use only jupyter launch.<br>find ait-sdk and install.|no edit|\n",
    "| 3|create requirements and pip install|3|Use only jupyter launch.<br>create requirements.txt.<br>And install by requirements.txt.|should edit(second cell, you set use modules.)|\n",
    "| 4|import|2|you should write use import modules.<br>but bottom lines do not edit.|should edit(first cell, you import your moduel.)|\n",
    "| 5|create manifest|1|Use only jupyter launch.<br>create ait.manifest.json.|should edit|\n",
    "| 6|create input|1|Use only jupyter launch.<br>create ait.input.json.|should edit|\n",
    "| 7|initialize|1|this cell is initialize for ait progress.|no edit|\n",
    "| 8|functions|N|you defined measures, resources, downloads in ait.manifesit.json. <br>Define any functions to add these.|should edit|\n",
    "| 9|main|1|Read the data set or model and calls the function defined in `functions-area`.|should edit|\n",
    "|10|entrypoint|1|Call the main function.|no edit|\n",
    "|11|license attribute set|1|Use only notebook launch.<br>Setting attribute for license.|should edit|\n",
    "|12|prepare deploy|1|Use only notebook launch.<br>Convert to python programs and create dag.py.|no edit|\n",
    "\n",
    "## notebook template revision history\n",
    "\n",
    "### 1.0.1 2020/10/21\n",
    "\n",
    "* add revision history\n",
    "* separate `create requirements and pip install` editable and noeditable\n",
    "* separate `import` editable and noeditable\n",
    "\n",
    "### 1.0.0 2020/10/12\n",
    "\n",
    "* new cerarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:flags set\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "# Determine whether to start AIT or jupyter by startup argument\n",
    "import sys\n",
    "is_ait_launch = (len(sys.argv) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-20.3.2-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.3.1\n",
      "    Uninstalling pip-20.3.1:\n",
      "      Successfully uninstalled pip-20.3.1\n",
      "Successfully installed pip-20.3.2\n",
      "Processing ./ait_sdk-0.1.4-py3-none-any.whl\n",
      "Collecting numpy<=1.19.3\n",
      "  Downloading numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 9.4 MB/s eta 0:00:01    |███████████████▏                | 7.1 MB 5.5 MB/s eta 0:00:02     |██████████████████████████      | 12.1 MB 9.4 MB/s eta 0:00:01     |████████████████████████████▎   | 13.1 MB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil<=5.7.3\n",
      "  Downloading psutil-5.7.3.tar.gz (465 kB)\n",
      "\u001b[K     |████████████████████████████████| 465 kB 11.5 MB/s eta 0:00:01     |█████████▏                      | 133 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbconvert<=6.0.7\n",
      "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting nbformat<=5.0.8\n",
      "  Using cached nbformat-5.0.8-py3-none-any.whl (172 kB)\n",
      "Collecting keras<=2.4.3\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting py-cpuinfo<=7.0.0\n",
      "  Downloading py-cpuinfo-7.0.0.tar.gz (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 3.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 21.4 MB/s eta 0:00:01    |███                             | 2.5 MB 11.8 MB/s eta 0:00:02     |███▋                            | 3.0 MB 11.8 MB/s eta 0:00:02     |████▎                           | 3.5 MB 11.8 MB/s eta 0:00:02     |█████████████▎                  | 10.8 MB 5.7 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 6.1 MB/s eta 0:00:01     |█████████████████████████       | 3.1 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting testpath\n",
      "  Using cached testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
      "Collecting jinja2>=2.4\n",
      "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Using cached nbclient-0.5.1-py3-none-any.whl (65 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.4.3-py3-none-any.whl\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting traitlets>=4.2\n",
      "  Using cached traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-3.2.1-py2.py3-none-any.whl (145 kB)\n",
      "Collecting jupyter-core\n",
      "  Using cached jupyter_core-4.7.0-py3-none-any.whl (82 kB)\n",
      "Collecting pygments>=2.4.1\n",
      "  Using cached Pygments-2.7.3-py3-none-any.whl (950 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Using cached MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting async-generator\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting nest-asyncio\n",
      "  Using cached nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
      "Collecting jupyter-client>=6.1.5\n",
      "  Using cached jupyter_client-6.1.7-py3-none-any.whl (108 kB)\n",
      "Collecting pyzmq>=13\n",
      "  Using cached pyzmq-20.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting tornado>=4.1\n",
      "  Using cached tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting ipython-genutils\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-51.0.0-py3-none-any.whl (785 kB)\n",
      "\u001b[K     |████████████████████████████████| 785 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attrs>=17.4.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting six>=1.11.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Using cached pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting decorator\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-20.8-py2.py3-none-any.whl (39 kB)\n",
      "Collecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Building wheels for collected packages: psutil, py-cpuinfo, pyyaml\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.3-cp36-cp36m-linux_x86_64.whl size=288622 sha256=b5e346d5c5e9bbdee0c8f559caf9e38c3fd9351803f54c333a124d1e86c424fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/fa/ad/67/90bbaacdcfe970960dd5158397f23a6579b51d853720d7856d\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-py3-none-any.whl size=20299 sha256=1421bc854737c35556e3879851394fae5457dcf59f2ef940a2a03b8b2287ff7b\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/6d/cc/73a126dc2e09fe56fcec0a7386d255762611fbed1c86d3bbcc\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=45919 sha256=5a8928b32f811473840713228f0d023a4343fc5cdf98ce8c130edde67262176c\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc\n",
      "Successfully built psutil py-cpuinfo pyyaml\n",
      "Installing collected packages: zipp, typing-extensions, six, ipython-genutils, decorator, traitlets, setuptools, pyrsistent, importlib-metadata, attrs, tornado, pyzmq, python-dateutil, pyparsing, jupyter-core, jsonschema, webencodings, pygments, packaging, numpy, nest-asyncio, nbformat, MarkupSafe, jupyter-client, cached-property, async-generator, testpath, scipy, pyyaml, pandocfilters, nbclient, mistune, jupyterlab-pygments, jinja2, h5py, entrypoints, defusedxml, bleach, py-cpuinfo, psutil, nbconvert, keras, ait-sdk\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.0\n",
      "    Uninstalling zipp-3.4.0:\n",
      "      Successfully uninstalled zipp-3.4.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: ipython-genutils\n",
      "    Found existing installation: ipython-genutils 0.2.0\n",
      "    Uninstalling ipython-genutils-0.2.0:\n",
      "      Successfully uninstalled ipython-genutils-0.2.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 4.3.3\n",
      "    Uninstalling traitlets-4.3.3:\n",
      "      Successfully uninstalled traitlets-4.3.3\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 51.0.0\n",
      "    Uninstalling setuptools-51.0.0:\n",
      "      Successfully uninstalled setuptools-51.0.0\n",
      "  Attempting uninstall: pyrsistent\n",
      "    Found existing installation: pyrsistent 0.17.3\n",
      "    Uninstalling pyrsistent-0.17.3:\n",
      "      Successfully uninstalled pyrsistent-0.17.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.1.1\n",
      "    Uninstalling importlib-metadata-3.1.1:\n",
      "      Successfully uninstalled importlib-metadata-3.1.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 20.3.0\n",
      "    Uninstalling attrs-20.3.0:\n",
      "      Successfully uninstalled attrs-20.3.0\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.1\n",
      "    Uninstalling tornado-6.1:\n",
      "      Successfully uninstalled tornado-6.1\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 20.0.0\n",
      "    Uninstalling pyzmq-20.0.0:\n",
      "      Successfully uninstalled pyzmq-20.0.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.7.0\n",
      "    Uninstalling jupyter-core-4.7.0:\n",
      "      Successfully uninstalled jupyter-core-4.7.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 3.2.0\n",
      "    Uninstalling jsonschema-3.2.0:\n",
      "      Successfully uninstalled jsonschema-3.2.0\n",
      "  Attempting uninstall: webencodings\n",
      "    Found existing installation: webencodings 0.5.1\n",
      "    Uninstalling webencodings-0.5.1:\n",
      "      Successfully uninstalled webencodings-0.5.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.7.3\n",
      "    Uninstalling Pygments-2.7.3:\n",
      "      Successfully uninstalled Pygments-2.7.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.7\n",
      "    Uninstalling packaging-20.7:\n",
      "      Successfully uninstalled packaging-20.7\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.4.3\n",
      "    Uninstalling nest-asyncio-1.4.3:\n",
      "      Successfully uninstalled nest-asyncio-1.4.3\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.0.8\n",
      "    Uninstalling nbformat-5.0.8:\n",
      "      Successfully uninstalled nbformat-5.0.8\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 6.1.7\n",
      "    Uninstalling jupyter-client-6.1.7:\n",
      "      Successfully uninstalled jupyter-client-6.1.7\n",
      "  Attempting uninstall: async-generator\n",
      "    Found existing installation: async-generator 1.10\n",
      "    Uninstalling async-generator-1.10:\n",
      "      Successfully uninstalled async-generator-1.10\n",
      "  Attempting uninstall: testpath\n",
      "    Found existing installation: testpath 0.4.4\n",
      "    Uninstalling testpath-0.4.4:\n",
      "      Successfully uninstalled testpath-0.4.4\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: pandocfilters\n",
      "    Found existing installation: pandocfilters 1.4.3\n",
      "    Uninstalling pandocfilters-1.4.3:\n",
      "      Successfully uninstalled pandocfilters-1.4.3\n",
      "  Attempting uninstall: nbclient\n",
      "    Found existing installation: nbclient 0.5.1\n",
      "    Uninstalling nbclient-0.5.1:\n",
      "      Successfully uninstalled nbclient-0.5.1\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: jupyterlab-pygments\n",
      "    Found existing installation: jupyterlab-pygments 0.1.2\n",
      "    Uninstalling jupyterlab-pygments-0.1.2:\n",
      "      Successfully uninstalled jupyterlab-pygments-0.1.2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 2.11.2\n",
      "    Uninstalling Jinja2-2.11.2:\n",
      "      Successfully uninstalled Jinja2-2.11.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: entrypoints\n",
      "    Found existing installation: entrypoints 0.3\n",
      "    Uninstalling entrypoints-0.3:\n",
      "      Successfully uninstalled entrypoints-0.3\n",
      "  Attempting uninstall: defusedxml\n",
      "    Found existing installation: defusedxml 0.6.0\n",
      "    Uninstalling defusedxml-0.6.0:\n",
      "      Successfully uninstalled defusedxml-0.6.0\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 3.2.1\n",
      "    Uninstalling bleach-3.2.1:\n",
      "      Successfully uninstalled bleach-3.2.1\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.0.7\n",
      "    Uninstalling nbconvert-6.0.7:\n",
      "      Successfully uninstalled nbconvert-6.0.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.3.0 requires h5py<2.11.0,>=2.10.0, but you have h5py 3.1.0 which is incompatible.\n",
      "tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.3 which is incompatible.\n",
      "tensorflow 2.3.0 requires scipy==1.4.1, but you have scipy 1.5.4 which is incompatible.\u001b[0m\n",
      "Successfully installed MarkupSafe-1.1.1 ait-sdk-0.1.4 async-generator-1.10 attrs-20.3.0 bleach-3.2.1 cached-property-1.5.2 decorator-4.4.2 defusedxml-0.6.0 entrypoints-0.3 h5py-3.1.0 importlib-metadata-3.3.0 ipython-genutils-0.2.0 jinja2-2.11.2 jsonschema-3.2.0 jupyter-client-6.1.7 jupyter-core-4.7.0 jupyterlab-pygments-0.1.2 keras-2.4.3 mistune-0.8.4 nbclient-0.5.1 nbconvert-6.0.7 nbformat-5.0.8 nest-asyncio-1.4.3 numpy-1.19.3 packaging-20.8 pandocfilters-1.4.3 psutil-5.7.3 py-cpuinfo-7.0.0 pygments-2.7.3 pyparsing-2.4.7 pyrsistent-0.17.3 python-dateutil-2.8.1 pyyaml-5.3.1 pyzmq-20.0.0 scipy-1.5.4 setuptools-51.0.0 six-1.15.0 testpath-0.4.4 tornado-6.1 traitlets-4.3.3 typing-extensions-3.7.4.3 webencodings-0.5.1 zipp-3.4.0\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:ait-sdk install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    # get ait-sdk file name\n",
    "    from pathlib import Path\n",
    "    from glob import glob\n",
    "    import re\n",
    "\n",
    "    def numericalSort(value):\n",
    "        numbers = re.compile(r'(\\d+)')\n",
    "        parts = numbers.split(value)\n",
    "        parts[1::2] = map(int, parts[1::2])\n",
    "        return parts\n",
    "    latest_sdk_file_path=sorted(glob('../lib/*.whl'), key=numericalSort)[-1]\n",
    "\n",
    "    ait_sdk_name = Path(latest_sdk_file_path).name\n",
    "    \n",
    "    # copy to develop dir\n",
    "    import shutil\n",
    "    current_dir = %pwd\n",
    "    shutil.copyfile(f'../lib/{ait_sdk_name}', f'{current_dir}/{ait_sdk_name}')\n",
    "\n",
    "    # install ait-sdk\n",
    "    !pip install --upgrade pip\n",
    "    !pip install --force-reinstall ./$ait_sdk_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_requirements_generator import AITRequirementsGenerator\n",
    "    requirements_generator = AITRequirementsGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package('Cython')\n",
    "    requirements_generator.add_package('docopt')\n",
    "    requirements_generator.add_package('clint')\n",
    "    requirements_generator.add_package('crontab')\n",
    "    requirements_generator.add_package('tablib')\n",
    "    requirements_generator.add_package('matplotlib')\n",
    "    requirements_generator.add_package('Pillow')\n",
    "    requirements_generator.add_package('pycocotools')\n",
    "    requirements_generator.add_package('tensorflow','2.3.0')\n",
    "    requirements_generator.add_package('lxml')\n",
    "    requirements_generator.add_package('tf_slim')\n",
    "    requirements_generator.add_package('pandas')\n",
    "    requirements_generator.add_package('numpy')\n",
    "    requirements_generator.add_package('ipython')\n",
    "    requirements_generator.add_package('zipp','3.1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./ait_sdk-0.1.4-py3-none-any.whl\n",
      "Collecting Cython\n",
      "  Downloading Cython-0.29.21-cp36-cp36m-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 3.1 MB/s eta 0:00:01     |████████████████▎               | 1.0 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting clint\n",
      "  Downloading clint-0.5.1.tar.gz (29 kB)\n",
      "Collecting crontab\n",
      "  Downloading crontab-0.22.9.tar.gz (20 kB)\n",
      "Collecting tablib\n",
      "  Downloading tablib-3.0.0-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 6)) (3.3.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 7)) (8.0.1)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 9)) (2.3.0)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.6.2-cp36-cp36m-manylinux1_x86_64.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 8.7 MB/s eta 0:00:01     |██████████████████████▉         | 4.0 MB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tf_slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 75 kB/s  eta 0:00:01     |███████████████████▊            | 5.9 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 13)) (1.19.3)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from -r /workdir/root/develop/requirements.txt (line 14)) (7.16.1)\n",
      "Collecting zipp==3.1.0\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: nbformat<=5.0.8 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (5.0.8)\n",
      "Requirement already satisfied: psutil<=5.7.3 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (5.7.3)\n",
      "Requirement already satisfied: keras<=2.4.3 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (2.4.3)\n",
      "Requirement already satisfied: nbconvert<=6.0.7 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (6.0.7)\n",
      "Requirement already satisfied: py-cpuinfo<=7.0.0 in /usr/local/lib/python3.6/dist-packages (from ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (7.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (3.14.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 7.9 MB/s eta 0:00:01    |███▋                            | 2.3 MB 8.7 MB/s eta 0:00:03     |██████████▊                     | 6.8 MB 8.7 MB/s eta 0:00:02     |█████████████▉                  | 8.7 MB 8.7 MB/s eta 0:00:02     |████████████████                | 10.1 MB 5.0 MB/s eta 0:00:02     |█████████████████████▎          | 13.4 MB 5.0 MB/s eta 0:00:02     |██████████████████████████▋     | 16.7 MB 5.0 MB/s eta 0:00:01     |████████████████████████████    | 17.7 MB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (0.30.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.15.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (0.3.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.34.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.12.1)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 3.5 MB/s eta 0:00:01     |██████▉                         | 5.6 MB 10.0 MB/s eta 0:00:03     |█████████▊                      | 7.9 MB 5.3 MB/s eta 0:00:04     |███████████▋                    | 9.5 MB 5.3 MB/s eta 0:00:04     |████████████▏                   | 9.9 MB 5.3 MB/s eta 0:00:04     |██████████████████▏             | 14.8 MB 3.3 MB/s eta 0:00:04     |██████████████████▋             | 15.1 MB 3.3 MB/s eta 0:00:04     |█████████████████████████▋      | 20.9 MB 3.3 MB/s eta 0:00:02     |█████████████████████████████▋  | 24.1 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (2.4.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (0.11.0)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 4.9 MB/s eta 0:00:01     |████████▌                       | 757 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.4.3->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (5.3.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (2.7.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (3.2.1)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (4.7.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.3)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (2.11.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (1.4.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.6.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (4.3.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (1.1.1)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (1.4.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (6.1.7)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (20.0.0)\n",
      "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (2.8.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (20.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (51.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (3.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.17.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (2.25.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.7.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (2.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r /workdir/root/develop/requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (4.4.2)\n",
      "Collecting args\n",
      "  Downloading args-0.1.0.tar.gz (3.0 kB)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->-r /workdir/root/develop/requirements.txt (line 14)) (0.7.5)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.6/dist-packages (from ipython->-r /workdir/root/develop/requirements.txt (line 14)) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython->-r /workdir/root/develop/requirements.txt (line 14)) (3.0.8)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython->-r /workdir/root/develop/requirements.txt (line 14)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython->-r /workdir/root/develop/requirements.txt (line 14)) (0.17.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython->-r /workdir/root/develop/requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /workdir/root/develop/requirements.txt (line 14)) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /workdir/root/develop/requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /workdir/root/develop/requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /workdir/root/develop/requirements.txt (line 6)) (0.10.0)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (20.8)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert<=6.0.7->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat<=5.0.8->ait-sdk==0.1.4->-r /workdir/root/develop/requirements.txt (line 16)) (3.7.4.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect->ipython->-r /workdir/root/develop/requirements.txt (line 14)) (0.6.0)\n",
      "ait-sdk is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Building wheels for collected packages: clint, crontab, docopt, pycocotools, args\n",
      "  Building wheel for clint (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clint: filename=clint-0.5.1-py3-none-any.whl size=35198 sha256=2ddd52f8783daac495aea6a08dac230d32bd8450022f8d08d18feb70346d8899\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/8d/ae/80f0435a2ae1e23dfa586106a44a0a32968d553e6fcf61d8fb\n",
      "  Building wheel for crontab (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crontab: filename=crontab-0.22.9-py3-none-any.whl size=10502 sha256=2e51f0fe69960ed13b1ccb0d2e488fc890ba9e54a575d3fb02f838f893a17486\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/a1/fb/d348ecb11fff1f04102c9c867824ce04635b6b2390ca51183d\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=19852 sha256=c1839fd7439b027c9f94835277512f4b62c30258c55a3db2f7b0cc0b10a0ffe9\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/2a/fa/4d7a888e69774d5e6e855d190a8a51b357d77cc05eb1c097c9\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp36-cp36m-linux_x86_64.whl size=266359 sha256=edb4054f9ff4cb845ca43d2f41cae4467546e2dab17e4eb19d3f07246ca54217\n",
      "  Stored in directory: /root/.cache/pip/wheels/d8/c2/ba/8f5306f921c2e79ad7b09effdfed6bd966cfcf8c6fe55422d6\n",
      "  Building wheel for args (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for args: filename=args-0.1.0-py3-none-any.whl size=4239 sha256=d0f64dad6b65c22ce3e12eb0121d14add989ab928e705428d574244d948cbe26\n",
      "  Stored in directory: /root/.cache/pip/wheels/66/0a/c0/b28d8c7e7a0cfa9117a1f2fa66bcfeb95a40aff78a28e261eb\n",
      "Successfully built clint crontab docopt pycocotools args\n",
      "Installing collected packages: zipp, numpy, scipy, h5py, pytz, Cython, args, tf-slim, tablib, pycocotools, pandas, lxml, docopt, crontab, clint\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.0\n",
      "    Uninstalling zipp-3.4.0:\n",
      "      Successfully uninstalled zipp-3.4.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.3\n",
      "    Uninstalling numpy-1.19.3:\n",
      "      Successfully uninstalled numpy-1.19.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "Successfully installed Cython-0.29.21 args-0.1.0 clint-0.5.1 crontab-0.22.9 docopt-0.6.2 h5py-2.10.0 lxml-4.6.2 numpy-1.18.5 pandas-1.1.5 pycocotools-2.0.2 pytz-2020.4 scipy-1.4.1 tablib-3.0.0 tf-slim-1.1.0 zipp-3.1.0\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:create requirements and pip install\n",
    "# do not edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package(f'./{ait_sdk_name}')\n",
    "    requirements_path = requirements_generator.create_requirements(current_dir)\n",
    "\n",
    "    !pip install -r $requirements_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:import\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "# import if you need modules cell\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import pathlib\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from os import makedirs, path\n",
    "from collections import Iterable\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:import\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "# must use modules\n",
    "import shutil  # do not remove\n",
    "from ait_sdk.common.files.ait_input import AITInput  # do not remove\n",
    "from ait_sdk.common.files.ait_output import AITOutput  # do not remove\n",
    "from ait_sdk.common.files.ait_manifest import AITManifest  # do not remove\n",
    "from ait_sdk.develop.ait_path_helper import AITPathHelper  # do not remove\n",
    "from ait_sdk.utils.logging import get_logger, log, get_log_path  # do not remove\n",
    "from ait_sdk.develop.annotation import measures, resources, downloads, ait_main  # do not remove\n",
    "# must use modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create manifest\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_manifest_generator import AITManifestGenerator\n",
    "    \n",
    "    manifest_genenerator = AITManifestGenerator(current_dir)\n",
    "    manifest_genenerator.set_ait_name('eval_bdd100k_aicc_tf2.3')\n",
    "    manifest_genenerator.set_ait_description('''The image classification model infers the image data (.jpg).\n",
    "Compare the inference result with the correct answer data (.json).\n",
    "Output the coverage of the comparison result.\n",
    "!!!Caution!!!\n",
    "Please set the memory allocation of docker to 4GB or more.''')\n",
    "    manifest_genenerator.set_ait_author('AIST')\n",
    "    manifest_genenerator.set_ait_email('')\n",
    "    manifest_genenerator.set_ait_version('0.1')\n",
    "    manifest_genenerator.set_ait_quality('https://airc.aist.go.jp/aiqm/quality/internal/Accuracy_of_trained_model')\n",
    "    manifest_genenerator.set_ait_reference('')\n",
    "    manifest_genenerator.add_ait_inventories(name='trained_model_checkpoint', \n",
    "                                             type_='model', \n",
    "                                             description='trained_model_checkpoint', \n",
    "                                             format_=['zip'], \n",
    "                                             schema='https://www.tensorflow.org/guide/saved_model')\n",
    "    manifest_genenerator.add_ait_inventories(name='trained_model_graph', \n",
    "                                             type_='model', \n",
    "                                             description='trained_model_graph', \n",
    "                                             format_=['zip'], \n",
    "                                             schema='https://www.tensorflow.org/guide/saved_model')\n",
    "    manifest_genenerator.add_ait_inventories(name='trained_model_protobuf', \n",
    "                                             type_='model', \n",
    "                                             description='trained_model_protobuf', \n",
    "                                             format_=['zip'], \n",
    "                                             schema='https://www.tensorflow.org/guide/saved_model')\n",
    "    manifest_genenerator.add_ait_inventories(name='test_set_images', \n",
    "                                             type_='dataset', \n",
    "                                             description='image_dataset（bdd100K）', \n",
    "                                             format_=['zip'], \n",
    "                                             schema='https://bdd-data.berkeley.edu/')\n",
    "    manifest_genenerator.add_ait_inventories(name='test_set_labels', \n",
    "                                             type_='dataset', \n",
    "                                             description='image_label_dataset（bdd100K）', \n",
    "                                             format_=['json'], \n",
    "                                             schema='https://bdd-data.berkeley.edu/')\n",
    "    manifest_genenerator.add_ait_inventories(name='labels_define', \n",
    "                                             type_='dataset', \n",
    "                                             description='labels_define', \n",
    "                                             format_=['txt'], \n",
    "                                             schema='https://github.com/tensorflow/models/tree/master/research/object_detection/data')\n",
    "    manifest_genenerator.add_ait_measures(name='traffic_sign_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of traffic_sign', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='traffic_light_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of traffic_light', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='car_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of car', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='rider_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of rider', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='motor_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of motor', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='person_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of person', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='bus_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of bus', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='truck_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of truck', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='bike_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of bike', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_measures(name='train_accuracy', \n",
    "                                          type_='float', \n",
    "                                          description='accuracy predicted of train', \n",
    "                                          structure='single')\n",
    "    manifest_genenerator.add_ait_resources(name='all_label_accuracy_csv', \n",
    "                                           path='/usr/local/qai/resources/1/all_label_accuracy.csv', \n",
    "                                           type_='text', \n",
    "                                           description='accuracy of all label')\n",
    "    manifest_genenerator.add_ait_resources(name='all_label_accuracy_png', \n",
    "                                           path='/usr/local/qai/resources/2/all_label_accuracy.png', \n",
    "                                           type_='picture', \n",
    "                                           description='accuracy of all label')\n",
    "    manifest_genenerator.add_ait_downloads(name='Log', \n",
    "                                           path='/usr/local/qai/downloads/1/ait.log', \n",
    "                                           description='AIT_log')\n",
    "    manifest_genenerator.add_ait_downloads(name='each_label_accuracy', \n",
    "                                           path='/usr/local/qai/downloads/2/each_label_accuracy.csv', \n",
    "                                           description='accuracy of each label')\n",
    "    manifest_genenerator.add_ait_downloads(name='each_picture', \n",
    "                                           path='/usr/local/qai/downloads/3/{}predict.jpg', \n",
    "                                           description='predict of each picture')\n",
    "    manifest_path = manifest_genenerator.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:create input\n",
    "# should edit\n",
    "#########################################\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_input_generator import AITInputGenerator\n",
    "    input_generator = AITInputGenerator(manifest_path)\n",
    "    input_generator.add_ait_inventories(name='trained_model_checkpoint',\n",
    "                                        value='trained_model_checkpoint/trained_model_checkpoint.zip')\n",
    "    input_generator.add_ait_inventories(name='trained_model_graph',\n",
    "                                        value='trained_model_graph/trained_model_graph.zip')\n",
    "    input_generator.add_ait_inventories(name='trained_model_protobuf',\n",
    "                                        value='trained_model_protobuf/trained_model_protobuf.zip')\n",
    "    input_generator.add_ait_inventories(name='test_set_images',\n",
    "                                        value='test_set_images/test_set_images.zip')\n",
    "    input_generator.add_ait_inventories(name='test_set_labels',\n",
    "                                        value='test_set_labels/bdd100k_labels_images_val.json')\n",
    "    input_generator.add_ait_inventories(name='labels_define',\n",
    "                                        value='labels_define/mscoco_complete_label_map.pbtxt')\n",
    "    input_generator.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:initialize\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "ait_manifest = AITManifest()\n",
    "ait_input = AITInput(ait_manifest)\n",
    "ait_output = AITOutput(ait_manifest)\n",
    "\n",
    "if is_ait_launch:\n",
    "    # launch from AIT\n",
    "    current_dir = path.dirname(path.abspath(__file__))\n",
    "    path_helper = AITPathHelper(argv=sys.argv, ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "else:\n",
    "    # launch from jupyter notebook\n",
    "    # ait.input.json make in input_dir\n",
    "    input_dir = '/usr/local/qai/mnt/ip/job_args/1/1'\n",
    "    current_dir = %pwd\n",
    "    path_helper = AITPathHelper(argv=['', input_dir], ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "\n",
    "ait_input.read_json(path_helper.get_input_file_path())\n",
    "ait_manifest.read_json(path_helper.get_manifest_file_path())\n",
    "\n",
    "### do not edit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libssl-dev:amd64.\n",
      "(Reading database ... 18241 files and directories currently installed.)\n",
      "Preparing to unpack .../libssl-dev_1.1.1-1ubuntu2.1~18.04.7_amd64.deb ...\n",
      "Unpacking libssl-dev:amd64 (1.1.1-1ubuntu2.1~18.04.7) ...\n",
      "Selecting previously unselected package libffi-dev:amd64.\n",
      "Preparing to unpack .../libffi-dev_3.2.1-8_amd64.deb ...\n",
      "Unpacking libffi-dev:amd64 (3.2.1-8) ...\n",
      "Setting up libssl-dev:amd64 (1.1.1-1ubuntu2.1~18.04.7) ...\n",
      "Setting up libffi-dev:amd64 (3.2.1-8) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libpython-stdlib libpython2.7-minimal libpython2.7-stdlib libxslt1.1 python\n",
      "  python-bs4 python-chardet python-html5lib python-minimal\n",
      "  python-pkg-resources python-six python-webencodings python2.7\n",
      "  python2.7-minimal\n",
      "Suggested packages:\n",
      "  python-doc python-tk python-genshi python-lxml-dbg python-lxml-doc\n",
      "  python-setuptools python2.7-doc binfmt-support\n",
      "The following NEW packages will be installed:\n",
      "  libpython-stdlib libpython2.7-minimal libpython2.7-stdlib libxslt1.1 python\n",
      "  python-bs4 python-chardet python-html5lib python-lxml python-minimal\n",
      "  python-pkg-resources python-six python-webencodings python2.7\n",
      "  python2.7-minimal\n",
      "0 upgraded, 15 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 5395 kB of archives.\n",
      "After this operation, 24.5 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython2.7-minimal amd64 2.7.17-1~18.04ubuntu1.2 [335 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python2.7-minimal amd64 2.7.17-1~18.04ubuntu1.2 [1290 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-minimal amd64 2.7.15~rc1-1 [28.1 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython2.7-stdlib amd64 2.7.17-1~18.04ubuntu1.2 [1916 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python2.7 amd64 2.7.17-1~18.04ubuntu1.2 [248 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-stdlib amd64 2.7.15~rc1-1 [7620 B]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python amd64 2.7.15~rc1-1 [140 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxslt1.1 amd64 1.1.29-5ubuntu0.2 [150 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.3 [899 kB]\n",
      "Fetched 5395 kB in 20s (271 kB/s)                                              \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libpython2.7-minimal:amd64.\n",
      "(Reading database ... 18393 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libpython2.7-minimal_2.7.17-1~18.04ubuntu1.2_amd64.deb ...\n",
      "Unpacking libpython2.7-minimal:amd64 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Selecting previously unselected package python2.7-minimal.\n",
      "Preparing to unpack .../1-python2.7-minimal_2.7.17-1~18.04ubuntu1.2_amd64.deb ...\n",
      "Unpacking python2.7-minimal (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Selecting previously unselected package python-minimal.\n",
      "Preparing to unpack .../2-python-minimal_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking python-minimal (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package libpython2.7-stdlib:amd64.\n",
      "Preparing to unpack .../3-libpython2.7-stdlib_2.7.17-1~18.04ubuntu1.2_amd64.deb ...\n",
      "Unpacking libpython2.7-stdlib:amd64 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Selecting previously unselected package python2.7.\n",
      "Preparing to unpack .../4-python2.7_2.7.17-1~18.04ubuntu1.2_amd64.deb ...\n",
      "Unpacking python2.7 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Selecting previously unselected package libpython-stdlib:amd64.\n",
      "Preparing to unpack .../5-libpython-stdlib_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking libpython-stdlib:amd64 (2.7.15~rc1-1) ...\n",
      "Setting up libpython2.7-minimal:amd64 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Setting up python2.7-minimal (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Linking and byte-compiling packages for runtime python2.7...\n",
      "Setting up python-minimal (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package python.\n",
      "(Reading database ... 19144 files and directories currently installed.)\n",
      "Preparing to unpack .../0-python_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking python (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package libxslt1.1:amd64.\n",
      "Preparing to unpack .../1-libxslt1.1_1.1.29-5ubuntu0.2_amd64.deb ...\n",
      "Unpacking libxslt1.1:amd64 (1.1.29-5ubuntu0.2) ...\n",
      "Selecting previously unselected package python-bs4.\n",
      "Preparing to unpack .../2-python-bs4_4.6.0-1_all.deb ...\n",
      "Unpacking python-bs4 (4.6.0-1) ...\n",
      "Selecting previously unselected package python-pkg-resources.\n",
      "Preparing to unpack .../3-python-pkg-resources_39.0.1-2_all.deb ...\n",
      "Unpacking python-pkg-resources (39.0.1-2) ...\n",
      "Selecting previously unselected package python-chardet.\n",
      "Preparing to unpack .../4-python-chardet_3.0.4-1_all.deb ...\n",
      "Unpacking python-chardet (3.0.4-1) ...\n",
      "Selecting previously unselected package python-six.\n",
      "Preparing to unpack .../5-python-six_1.11.0-2_all.deb ...\n",
      "Unpacking python-six (1.11.0-2) ...\n",
      "Selecting previously unselected package python-webencodings.\n",
      "Preparing to unpack .../6-python-webencodings_0.5-2_all.deb ...\n",
      "Unpacking python-webencodings (0.5-2) ...\n",
      "Selecting previously unselected package python-html5lib.\n",
      "Preparing to unpack .../7-python-html5lib_0.999999999-1_all.deb ...\n",
      "Unpacking python-html5lib (0.999999999-1) ...\n",
      "Selecting previously unselected package python-lxml:amd64.\n",
      "Preparing to unpack .../8-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n",
      "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
      "Setting up libxslt1.1:amd64 (1.1.29-5ubuntu0.2) ...\n",
      "Setting up libpython2.7-stdlib:amd64 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Setting up python2.7 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Setting up libpython-stdlib:amd64 (2.7.15~rc1-1) ...\n",
      "Setting up python (2.7.15~rc1-1) ...\n",
      "Setting up python-pkg-resources (39.0.1-2) ...\n",
      "Setting up python-six (1.11.0-2) ...\n",
      "Setting up python-bs4 (4.6.0-1) ...\n",
      "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
      "Setting up python-webencodings (0.5-2) ...\n",
      "Setting up python-chardet (3.0.4-1) ...\n",
      "Setting up python-html5lib (0.999999999-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Note, selecting 'libxslt1-dev' instead of 'libxslt-dev'\n",
      "curl is already the newest version (7.58.0-2ubuntu3.12).\n",
      "libxml2 is already the newest version (2.9.4+dfsg1-6.1ubuntu1.3).\n",
      "libxml2 set to manually installed.\n",
      "The following additional packages will be installed:\n",
      "  gir1.2-harfbuzz-0.0 icu-devtools libelf1 libfreetype6 libglib2.0-bin\n",
      "  libglib2.0-dev libglib2.0-dev-bin libgraphite2-3 libgraphite2-dev\n",
      "  libharfbuzz-dev libharfbuzz-gobject0 libharfbuzz-icu0 libharfbuzz0b\n",
      "  libicu-dev libicu-le-hb-dev libicu-le-hb0 libiculx60 libpcre16-3\n",
      "  libpcre3-dev libpcre32-3 libpcrecpp0v5 libpng16-16 libpython-dev\n",
      "  libpython2.7 libpython2.7-dev pkg-config python2.7-dev zlib1g-dev\n",
      "Suggested packages:\n",
      "  libglib2.0-doc libgraphite2-utils icu-doc\n",
      "The following NEW packages will be installed:\n",
      "  gir1.2-harfbuzz-0.0 icu-devtools libelf1 libfreetype6 libglib2.0-bin\n",
      "  libglib2.0-dev libglib2.0-dev-bin libgraphite2-3 libgraphite2-dev\n",
      "  libharfbuzz-dev libharfbuzz-gobject0 libharfbuzz-icu0 libharfbuzz0b\n",
      "  libicu-dev libicu-le-hb-dev libicu-le-hb0 libiculx60 libpcre16-3\n",
      "  libpcre3-dev libpcre32-3 libpcrecpp0v5 libpng16-16 libpython-dev\n",
      "  libpython2.7 libpython2.7-dev libxml2-dev libxslt1-dev pkg-config python-dev\n",
      "  python2.7-dev zlib1g-dev\n",
      "0 upgraded, 31 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 43.7 MB of archives.\n",
      "After this operation, 112 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libelf1 amd64 0.170-0.4ubuntu0.1 [44.8 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpng16-16 amd64 1.6.34-1ubuntu0.18.04.2 [176 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libfreetype6 amd64 2.8.1-2ubuntu2.1 [335 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgraphite2-3 amd64 1.3.11-2 [78.7 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libharfbuzz0b amd64 1.7.2-1ubuntu1 [232 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-harfbuzz-0.0 amd64 1.7.2-1ubuntu1 [18.6 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 icu-devtools amd64 60.2-3ubuntu3.1 [179 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-bin amd64 2.56.4-0ubuntu0.18.04.6 [68.8 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-dev-bin amd64 2.56.4-0ubuntu0.18.04.6 [102 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpcre16-3 amd64 2:8.39-9 [147 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpcre32-3 amd64 2:8.39-9 [138 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpcrecpp0v5 amd64 2:8.39-9 [15.3 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpcre3-dev amd64 2:8.39-9 [537 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 pkg-config amd64 0.29.1-0ubuntu2 [45.0 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 zlib1g-dev amd64 1:1.2.11.dfsg-0ubuntu2 [176 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-dev amd64 2.56.4-0ubuntu0.18.04.6 [1385 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgraphite2-dev amd64 1.3.11-2 [14.5 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libharfbuzz-icu0 amd64 1.7.2-1ubuntu1 [5604 B]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libharfbuzz-gobject0 amd64 1.7.2-1ubuntu1 [13.4 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libicu-le-hb0 amd64 1.0.3+git161113-4 [14.3 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libiculx60 amd64 60.2-3ubuntu3.1 [19.0 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libicu-le-hb-dev amd64 1.0.3+git161113-4 [29.5 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libicu-dev amd64 60.2-3ubuntu3.1 [8889 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libharfbuzz-dev amd64 1.7.2-1ubuntu1 [302 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython2.7 amd64 2.7.17-1~18.04ubuntu1.2 [1054 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython2.7-dev amd64 2.7.17-1~18.04ubuntu1.2 [28.3 MB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-dev amd64 2.7.15~rc1-1 [7684 B]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxml2-dev amd64 2.9.4+dfsg1-6.1ubuntu1.3 [756 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxslt1-dev amd64 1.1.29-5ubuntu0.2 [407 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python2.7-dev amd64 2.7.17-1~18.04ubuntu1.2 [279 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dev amd64 2.7.15~rc1-1 [1256 B]\n",
      "Fetched 43.7 MB in 2min 34s (283 kB/s)                                         \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libelf1:amd64.\n",
      "(Reading database ... 19476 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libelf1_0.170-0.4ubuntu0.1_amd64.deb ...\n",
      "Unpacking libelf1:amd64 (0.170-0.4ubuntu0.1) ...\n",
      "Selecting previously unselected package libpng16-16:amd64.\n",
      "Preparing to unpack .../01-libpng16-16_1.6.34-1ubuntu0.18.04.2_amd64.deb ...\n",
      "Unpacking libpng16-16:amd64 (1.6.34-1ubuntu0.18.04.2) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../02-libfreetype6_2.8.1-2ubuntu2.1_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.8.1-2ubuntu2.1) ...\n",
      "Selecting previously unselected package libgraphite2-3:amd64.\n",
      "Preparing to unpack .../03-libgraphite2-3_1.3.11-2_amd64.deb ...\n",
      "Unpacking libgraphite2-3:amd64 (1.3.11-2) ...\n",
      "Selecting previously unselected package libharfbuzz0b:amd64.\n",
      "Preparing to unpack .../04-libharfbuzz0b_1.7.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking libharfbuzz0b:amd64 (1.7.2-1ubuntu1) ...\n",
      "Selecting previously unselected package gir1.2-harfbuzz-0.0:amd64.\n",
      "Preparing to unpack .../05-gir1.2-harfbuzz-0.0_1.7.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking gir1.2-harfbuzz-0.0:amd64 (1.7.2-1ubuntu1) ...\n",
      "Selecting previously unselected package icu-devtools.\n",
      "Preparing to unpack .../06-icu-devtools_60.2-3ubuntu3.1_amd64.deb ...\n",
      "Unpacking icu-devtools (60.2-3ubuntu3.1) ...\n",
      "Selecting previously unselected package libglib2.0-bin.\n",
      "Preparing to unpack .../07-libglib2.0-bin_2.56.4-0ubuntu0.18.04.6_amd64.deb ...\n",
      "Unpacking libglib2.0-bin (2.56.4-0ubuntu0.18.04.6) ...\n",
      "Selecting previously unselected package libglib2.0-dev-bin.\n",
      "Preparing to unpack .../08-libglib2.0-dev-bin_2.56.4-0ubuntu0.18.04.6_amd64.deb ...\n",
      "Unpacking libglib2.0-dev-bin (2.56.4-0ubuntu0.18.04.6) ...\n",
      "Selecting previously unselected package libpcre16-3:amd64.\n",
      "Preparing to unpack .../09-libpcre16-3_2%3a8.39-9_amd64.deb ...\n",
      "Unpacking libpcre16-3:amd64 (2:8.39-9) ...\n",
      "Selecting previously unselected package libpcre32-3:amd64.\n",
      "Preparing to unpack .../10-libpcre32-3_2%3a8.39-9_amd64.deb ...\n",
      "Unpacking libpcre32-3:amd64 (2:8.39-9) ...\n",
      "Selecting previously unselected package libpcrecpp0v5:amd64.\n",
      "Preparing to unpack .../11-libpcrecpp0v5_2%3a8.39-9_amd64.deb ...\n",
      "Unpacking libpcrecpp0v5:amd64 (2:8.39-9) ...\n",
      "Selecting previously unselected package libpcre3-dev:amd64.\n",
      "Preparing to unpack .../12-libpcre3-dev_2%3a8.39-9_amd64.deb ...\n",
      "Unpacking libpcre3-dev:amd64 (2:8.39-9) ...\n",
      "Selecting previously unselected package pkg-config.\n",
      "Preparing to unpack .../13-pkg-config_0.29.1-0ubuntu2_amd64.deb ...\n",
      "Unpacking pkg-config (0.29.1-0ubuntu2) ...\n",
      "Selecting previously unselected package zlib1g-dev:amd64.\n",
      "Preparing to unpack .../14-zlib1g-dev_1%3a1.2.11.dfsg-0ubuntu2_amd64.deb ...\n",
      "Unpacking zlib1g-dev:amd64 (1:1.2.11.dfsg-0ubuntu2) ...\n",
      "Selecting previously unselected package libglib2.0-dev:amd64.\n",
      "Preparing to unpack .../15-libglib2.0-dev_2.56.4-0ubuntu0.18.04.6_amd64.deb ...\n",
      "Unpacking libglib2.0-dev:amd64 (2.56.4-0ubuntu0.18.04.6) ...\n",
      "Selecting previously unselected package libgraphite2-dev:amd64.\n",
      "Preparing to unpack .../16-libgraphite2-dev_1.3.11-2_amd64.deb ...\n",
      "Unpacking libgraphite2-dev:amd64 (1.3.11-2) ...\n",
      "Selecting previously unselected package libharfbuzz-icu0:amd64.\n",
      "Preparing to unpack .../17-libharfbuzz-icu0_1.7.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking libharfbuzz-icu0:amd64 (1.7.2-1ubuntu1) ...\n",
      "Selecting previously unselected package libharfbuzz-gobject0:amd64.\n",
      "Preparing to unpack .../18-libharfbuzz-gobject0_1.7.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking libharfbuzz-gobject0:amd64 (1.7.2-1ubuntu1) ...\n",
      "Selecting previously unselected package libicu-le-hb0:amd64.\n",
      "Preparing to unpack .../19-libicu-le-hb0_1.0.3+git161113-4_amd64.deb ...\n",
      "Unpacking libicu-le-hb0:amd64 (1.0.3+git161113-4) ...\n",
      "Selecting previously unselected package libiculx60:amd64.\n",
      "Preparing to unpack .../20-libiculx60_60.2-3ubuntu3.1_amd64.deb ...\n",
      "Unpacking libiculx60:amd64 (60.2-3ubuntu3.1) ...\n",
      "Selecting previously unselected package libicu-le-hb-dev:amd64.\n",
      "Preparing to unpack .../21-libicu-le-hb-dev_1.0.3+git161113-4_amd64.deb ...\n",
      "Unpacking libicu-le-hb-dev:amd64 (1.0.3+git161113-4) ...\n",
      "Selecting previously unselected package libicu-dev.\n",
      "Preparing to unpack .../22-libicu-dev_60.2-3ubuntu3.1_amd64.deb ...\n",
      "Unpacking libicu-dev (60.2-3ubuntu3.1) ...\n",
      "Selecting previously unselected package libharfbuzz-dev:amd64.\n",
      "Preparing to unpack .../23-libharfbuzz-dev_1.7.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking libharfbuzz-dev:amd64 (1.7.2-1ubuntu1) ...\n",
      "Selecting previously unselected package libpython2.7:amd64.\n",
      "Preparing to unpack .../24-libpython2.7_2.7.17-1~18.04ubuntu1.2_amd64.deb ...\n",
      "Unpacking libpython2.7:amd64 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Selecting previously unselected package libpython2.7-dev:amd64.\n",
      "Preparing to unpack .../25-libpython2.7-dev_2.7.17-1~18.04ubuntu1.2_amd64.deb ...\n",
      "Unpacking libpython2.7-dev:amd64 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Selecting previously unselected package libpython-dev:amd64.\n",
      "Preparing to unpack .../26-libpython-dev_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking libpython-dev:amd64 (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package libxml2-dev:amd64.\n",
      "Preparing to unpack .../27-libxml2-dev_2.9.4+dfsg1-6.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking libxml2-dev:amd64 (2.9.4+dfsg1-6.1ubuntu1.3) ...\n",
      "Selecting previously unselected package libxslt1-dev:amd64.\n",
      "Preparing to unpack .../28-libxslt1-dev_1.1.29-5ubuntu0.2_amd64.deb ...\n",
      "Unpacking libxslt1-dev:amd64 (1.1.29-5ubuntu0.2) ...\n",
      "Selecting previously unselected package python2.7-dev.\n",
      "Preparing to unpack .../29-python2.7-dev_2.7.17-1~18.04ubuntu1.2_amd64.deb ...\n",
      "Unpacking python2.7-dev (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Selecting previously unselected package python-dev.\n",
      "Preparing to unpack .../30-python-dev_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking python-dev (2.7.15~rc1-1) ...\n",
      "Setting up libglib2.0-dev-bin (2.56.4-0ubuntu0.18.04.6) ...\n",
      "Setting up libpng16-16:amd64 (1.6.34-1ubuntu0.18.04.2) ...\n",
      "Setting up libelf1:amd64 (0.170-0.4ubuntu0.1) ...\n",
      "Setting up libfreetype6:amd64 (2.8.1-2ubuntu2.1) ...\n",
      "Setting up libgraphite2-3:amd64 (1.3.11-2) ...\n",
      "Setting up pkg-config (0.29.1-0ubuntu2) ...\n",
      "Setting up libpython2.7:amd64 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Setting up libpcrecpp0v5:amd64 (2:8.39-9) ...\n",
      "Setting up libpcre32-3:amd64 (2:8.39-9) ...\n",
      "Setting up libpython2.7-dev:amd64 (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Setting up icu-devtools (60.2-3ubuntu3.1) ...\n",
      "Setting up libpcre16-3:amd64 (2:8.39-9) ...\n",
      "Setting up libglib2.0-bin (2.56.4-0ubuntu0.18.04.6) ...\n",
      "Setting up python2.7-dev (2.7.17-1~18.04ubuntu1.2) ...\n",
      "Setting up libgraphite2-dev:amd64 (1.3.11-2) ...\n",
      "Setting up zlib1g-dev:amd64 (1:1.2.11.dfsg-0ubuntu2) ...\n",
      "Setting up libpython-dev:amd64 (2.7.15~rc1-1) ...\n",
      "Setting up libpcre3-dev:amd64 (2:8.39-9) ...\n",
      "Setting up python-dev (2.7.15~rc1-1) ...\n",
      "Setting up libharfbuzz0b:amd64 (1.7.2-1ubuntu1) ...\n",
      "Setting up libglib2.0-dev:amd64 (2.56.4-0ubuntu0.18.04.6) ...\n",
      "Setting up gir1.2-harfbuzz-0.0:amd64 (1.7.2-1ubuntu1) ...\n",
      "Setting up libharfbuzz-gobject0:amd64 (1.7.2-1ubuntu1) ...\n",
      "Setting up libharfbuzz-icu0:amd64 (1.7.2-1ubuntu1) ...\n",
      "Setting up libicu-le-hb0:amd64 (1.0.3+git161113-4) ...\n",
      "Setting up libiculx60:amd64 (60.2-3ubuntu3.1) ...\n",
      "Processing triggers for libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.6) ...\n",
      "No schema files found: doing nothing.\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
      "Setting up libharfbuzz-dev:amd64 (1.7.2-1ubuntu1) ...\n",
      "Setting up libicu-le-hb-dev:amd64 (1.0.3+git161113-4) ...\n",
      "Setting up libicu-dev (60.2-3ubuntu3.1) ...\n",
      "Setting up libxml2-dev:amd64 (2.9.4+dfsg1-6.1ubuntu1.3) ...\n",
      "Setting up libxslt1-dev:amd64 (1.1.29-5ubuntu0.2) ...\n",
      "/tmp\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 167 kB of archives.\n",
      "After this operation, 558 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 unzip amd64 6.0-21ubuntu1 [167 kB]\n",
      "Fetched 167 kB in 2s (107 kB/s) \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 20759 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-21ubuntu1_amd64.deb ...\n",
      "Unpacking unzip (6.0-21ubuntu1) ...\n",
      "Setting up unzip (6.0-21ubuntu1) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   164  100   164    0     0    475      0 --:--:-- --:--:-- --:--:--   476\n",
      "100   653  100   653    0     0   1003      0 --:--:-- --:--:-- --:--:--  1003\n",
      "100 1519k  100 1519k    0     0   481k      0  0:00:03  0:00:03 --:--:--  621k\n",
      "Archive:  protoc-3.9.0-linux-x86_64.zip\n",
      "   creating: protoc3/include/\n",
      "   creating: protoc3/include/google/\n",
      "   creating: protoc3/include/google/protobuf/\n",
      "  inflating: protoc3/include/google/protobuf/empty.proto  \n",
      "  inflating: protoc3/include/google/protobuf/duration.proto  \n",
      "  inflating: protoc3/include/google/protobuf/timestamp.proto  \n",
      "  inflating: protoc3/include/google/protobuf/api.proto  \n",
      "  inflating: protoc3/include/google/protobuf/type.proto  \n",
      "  inflating: protoc3/include/google/protobuf/any.proto  \n",
      "  inflating: protoc3/include/google/protobuf/field_mask.proto  \n",
      "  inflating: protoc3/include/google/protobuf/descriptor.proto  \n",
      "  inflating: protoc3/include/google/protobuf/wrappers.proto  \n",
      "  inflating: protoc3/include/google/protobuf/struct.proto  \n",
      "   creating: protoc3/include/google/protobuf/compiler/\n",
      "  inflating: protoc3/include/google/protobuf/compiler/plugin.proto  \n",
      "  inflating: protoc3/include/google/protobuf/source_context.proto  \n",
      "   creating: protoc3/bin/\n",
      "  inflating: protoc3/bin/protoc      \n",
      "  inflating: protoc3/readme.txt      \n"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    \n",
    "    !apt-get update -yqq\n",
    "    !apt-get install gcc g++ make libffi-dev libssl-dev -yqq\n",
    "    !apt-get install python-lxml -y\n",
    "    !apt-get install python-dev libxml2 libxml2-dev libxslt-dev curl -y\n",
    "\n",
    "    !export PYTHONPATH=$PYTHONPATH:/tensorflow/models/research:/tensorflow/\n",
    "\n",
    "    %cd /tmp\n",
    "    !apt-get install -y unzip\n",
    "    !curl -OL https://github.com/google/protobuf/releases/download/v3.9.0/protoc-3.9.0-linux-x86_64.zip\n",
    "    !unzip -d protoc3 protoc-3.9.0-linux-x86_64.zip\n",
    "    !mv protoc3/bin/* /usr/local/bin/\n",
    "    !mv protoc3/include/* /usr/local/include/\n",
    "    !rm -rf protoc-3.9.0-linux-x86_64.zip protoc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.7).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\n",
      "Cloning into 'cocoapi'...\n",
      "remote: Enumerating objects: 975, done.\u001b[K\n",
      "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
      "Receiving objects: 100% (975/975), 11.72 MiB | 5.28 MiB/s, done.\n",
      "Resolving deltas: 100% (576/576), done.\n",
      "/tmp/cocoapi/PythonAPI\n",
      "running build_ext\n",
      "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.6\n",
      "creating build/temp.linux-x86_64-3.6/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.6/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
      "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.6\n",
      "creating build/lib.linux-x86_64-3.6/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/../common/maskApi.o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -o build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so -> pycocotools\n",
      "running build_ext\n",
      "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.6\n",
      "creating build/temp.linux-x86_64-3.6/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.6/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
      "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.6\n",
      "creating build/lib.linux-x86_64-3.6/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/../common/maskApi.o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -o build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating pycocotools.egg-info\n",
      "writing pycocotools.egg-info/PKG-INFO\n",
      "writing dependency_links to pycocotools.egg-info/dependency_links.txt\n",
      "writing requirements to pycocotools.egg-info/requires.txt\n",
      "writing top-level names to pycocotools.egg-info/top_level.txt\n",
      "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "reading manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
      "copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
      "copying pycocotools/mask.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
      "copying pycocotools/coco.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-36.pyc\n",
      "creating stub loader for pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-36.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "pycocotools.__pycache__._mask.cpython-36: module references __file__\n",
      "creating dist\n",
      "creating 'dist/pycocotools-2.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing pycocotools-2.0-py3.6-linux-x86_64.egg\n",
      "creating /usr/local/lib/python3.6/dist-packages/pycocotools-2.0-py3.6-linux-x86_64.egg\n",
      "Extracting pycocotools-2.0-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
      "Adding pycocotools 2.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.6/dist-packages/pycocotools-2.0-py3.6-linux-x86_64.egg\n",
      "Processing dependencies for pycocotools==2.0\n",
      "Searching for matplotlib==3.3.3\n",
      "Best match: matplotlib 3.3.3\n",
      "Adding matplotlib 3.3.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for Cython==0.29.21\n",
      "Best match: Cython 0.29.21\n",
      "Adding Cython 0.29.21 to easy-install.pth file\n",
      "Installing cygdb script to /usr/local/bin\n",
      "Installing cython script to /usr/local/bin\n",
      "Installing cythonize script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for setuptools==51.0.0\n",
      "Best match: setuptools 51.0.0\n",
      "Adding setuptools 51.0.0 to easy-install.pth file\n",
      "Installing easy_install script to /usr/local/bin\n",
      "Installing easy_install-3.8 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for numpy==1.18.5\n",
      "Best match: numpy 1.18.5\n",
      "Adding numpy 1.18.5 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.6 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for python-dateutil==2.8.1\n",
      "Best match: python-dateutil 2.8.1\n",
      "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for pyparsing==2.4.7\n",
      "Best match: pyparsing 2.4.7\n",
      "Adding pyparsing 2.4.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for Pillow==8.0.1\n",
      "Best match: Pillow 8.0.1\n",
      "Adding Pillow 8.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for kiwisolver==1.3.1\n",
      "Best match: kiwisolver 1.3.1\n",
      "Adding kiwisolver 1.3.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Finished processing dependencies for pycocotools==2.0\n",
      "/tensorflow\n",
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 87, done.\u001b[K\n",
      "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
      "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
      "remote: Total 49264 (delta 36), reused 49 (delta 3), pack-reused 49177\u001b[K\n",
      "Receiving objects: 100% (49264/49264), 558.63 MiB | 9.25 MiB/s, done.\n",
      "Resolving deltas: 100% (33926/33926), done.\n",
      "/tensorflow/models/research\n",
      "/workdir/root/develop\n"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    !apt-get install git -y\n",
    "    !git clone https://github.com/cocodataset/cocoapi.git\n",
    "    %cd /tmp/cocoapi/PythonAPI\n",
    "    !python3 setup.py build_ext --inplace\n",
    "    !rm -rf build\n",
    "    !python3 setup.py build_ext install\n",
    "    !rm -rf build\n",
    "\n",
    "    !mkdir /tensorflow\n",
    "    %cd /tensorflow\n",
    "    !git clone https://github.com/tensorflow/models.git\n",
    "    %cd /tensorflow/models/research\n",
    "    !protoc object_detection/protos/*.proto --python_out=.\n",
    "    \n",
    "    %cd /workdir/root/develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(Path().resolve(), '/tensorflow/models/research'))\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "g_total_accuracy = []\n",
    "\n",
    "resultFile = []\n",
    "# With a range of -1 you will get evrything\n",
    "limit_box_range = 0\n",
    "# Obtaining yolo results\n",
    "g_image_name = \"\"\n",
    "count_traffic_label = 0\n",
    "gt_list_boxes = []\n",
    "\n",
    "total_correct_predicted = [0,0,0,0,0,0,0,0,0,0]\n",
    "total_GT_correct_predicted = [0,0,0,0,0,0,0,0,0,0]\n",
    "total_predicted_per_label = [0,0,0,0,0,0,0,0,0,0]\n",
    "correct_predicted = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "jsonFileName = \"\"\n",
    "\n",
    "average_accuracy = []\n",
    "avg_acc_per_traffic_sign = []\n",
    "avg_acc_per_traffic_light = []\n",
    "avg_acc_per_car = []\n",
    "avg_acc_per_rider = []\n",
    "avg_acc_per_motor = []\n",
    "avg_acc_per_person = []\n",
    "avg_acc_per_bus = []\n",
    "avg_acc_per_truck = []\n",
    "avg_acc_per_bike = []\n",
    "avg_acc_per_train = []\n",
    "\n",
    "f_each = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_inference_for_single_image(model, image) -> np.ndarray:\n",
    "    image = np.asarray(image)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    # Run inference\n",
    "    model_fn = model.signatures['serving_default']\n",
    "    output_dict = model_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() \n",
    "                                for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "\n",
    "    # Handle models with masks:\n",
    "    if 'detection_masks' in output_dict:\n",
    "        # Reframe the the bbox mask to the image size.\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                            output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "                            image.shape[0], image.shape[1])\t\t\t\n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, tf.uint8)\n",
    "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_labels(label_path) -> np.ndarray:\n",
    "    labels = json.load(open(label_path, 'r'))\n",
    "    if not isinstance(labels, Iterable):\n",
    "        labels = [labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_boxes(objects) -> np.ndarray:\n",
    "    return [o for o in objects if ('box2d' in o and o['box2d'] is not None)\n",
    "            or ('box3d' in o and o['box3d'] is not None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_id_label(current_object_label) -> int:\n",
    "    if current_object_label == \"traffic sign\":\n",
    "        #traffic_sign = 0\n",
    "        return 0\n",
    "    elif current_object_label == \"traffic light\":\n",
    "        #traffic light = 1\n",
    "        return 1\n",
    "    elif current_object_label == \"car\":\n",
    "        #car = 2\n",
    "        return 2\n",
    "    elif current_object_label == \"rider\":\n",
    "        #rider = 3\n",
    "        return 3\n",
    "    elif current_object_label == \"motor\":\n",
    "        #motor = 4\n",
    "        return 4\n",
    "    elif current_object_label == \"person\":\n",
    "        #person = 5\n",
    "        return 5\n",
    "    elif current_object_label == \"bus\":\n",
    "        #bus = 6\n",
    "        return 6\n",
    "    elif current_object_label == \"truck\":\n",
    "        #truck = 7\n",
    "        return 7\n",
    "    elif current_object_label == \"bike\":\n",
    "        #bike = 8\n",
    "        return 8\n",
    "    elif current_object_label == \"train\":\n",
    "        #train = 9\n",
    "        return 9\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_label_from_id(id) -> str:\n",
    "    if id == 0:\n",
    "        return \"traffic sign\"\n",
    "    elif id == 1:\n",
    "        return \"traffic light\"\n",
    "    elif id == 2:\n",
    "        return \"car\"\n",
    "    elif id == 3:\n",
    "        return \"rider\"\n",
    "    elif id == 4:\n",
    "        return \"motor\"\n",
    "    elif id == 5:\n",
    "        return \"person\"\n",
    "    elif id == 6:\n",
    "        return \"bus\"\n",
    "    elif id == 7:\n",
    "        return \"truck\"\n",
    "    elif id == 8:\n",
    "        return \"bike\"\n",
    "    elif id == 9:\n",
    "        return \"train\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _adding_avg_label_from_id(id, value, avg_acc_per_traffic_sign, avg_acc_per_traffic_light, \n",
    "                                avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, \n",
    "                                avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train):\n",
    "    if id == 0:\n",
    "        avg_acc_per_traffic_sign.append(value)\n",
    "    elif id == 1:\n",
    "        avg_acc_per_traffic_light.append(value)\n",
    "    elif id == 2:\n",
    "        avg_acc_per_car.append(value)\n",
    "    elif id == 3:\n",
    "        avg_acc_per_rider.append(value)\n",
    "    elif id == 4:\n",
    "        avg_acc_per_motor.append(value)\n",
    "    elif id == 5:\n",
    "        avg_acc_per_person.append(value)\n",
    "    elif id == 6:\n",
    "        avg_acc_per_bus.append(value)\n",
    "    elif id == 7:\n",
    "        avg_acc_per_truck.append(value)\n",
    "    elif id == 8:\n",
    "        avg_acc_per_bike.append(value)\n",
    "    elif id == 9:\n",
    "        avg_acc_per_train.append(value)\n",
    "\n",
    "    return avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _search_image_information(objects, image_name) -> np.ndarray:\n",
    "    list_boxes = []\n",
    "    for counter,o in enumerate(objects):\n",
    "        if o['name'] != image_name:\n",
    "            continue\n",
    "\n",
    "        for b in _get_boxes(o[\"labels\"]):\n",
    "\n",
    "            current_object_label = b['category']\n",
    "\n",
    "            x1 = b['box2d']['x1']\n",
    "            y1 = b['box2d']['y1']\n",
    "            x2 = b['box2d']['x2']\n",
    "            y2 = b['box2d']['y2']\n",
    "\n",
    "            if abs(x1 - x2) < limit_box_range and abs(y1 - y2) < limit_box_range:\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Last value is to determine if this box has been found or not\n",
    "            list_boxes.append([current_object_label,x1,y1,x2,y2, False])\n",
    "\n",
    "        break\n",
    "\n",
    "    return list_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_labels_ground_truth(gt_list_boxes, total_GT_correct_predicted):\n",
    "    list_ground_truth = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for counter, box in enumerate(gt_list_boxes):\n",
    "        id = _get_id_label(box[0])\n",
    "        list_ground_truth[id] = list_ground_truth[id] + 1\n",
    "        total_GT_correct_predicted[id] = total_GT_correct_predicted[id] + 1\n",
    "    return list_ground_truth,total_GT_correct_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _averageOfList(num) -> float:\n",
    "    sumOfNumbers = 0\n",
    "    for t in num:\n",
    "        sumOfNumbers = sumOfNumbers + t\n",
    "\n",
    "    avg = sumOfNumbers / len(num)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSONファイルと推論結果を比較する\n",
    "def _compare_json(gt_list_boxes, objects, total_GT_correct_predicted,avg_acc_per_traffic_sign, avg_acc_per_traffic_light, \n",
    "                                avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, \n",
    "                                avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train) -> None:\n",
    "\n",
    "    for line in resultFile:\n",
    "\n",
    "        listWords = line.split(\" \")\n",
    "        if (listWords[0] == \"Enter\"):\n",
    "            # CHECK ACCURACY OF PREVIOUS IMAGE\n",
    "            if len(gt_list_boxes) > 0:\n",
    "                total_labels = len(gt_list_boxes)\n",
    "\n",
    "                list_ground_truth,total_GT_correct_predicted = _load_labels_ground_truth(gt_list_boxes,total_GT_correct_predicted)\n",
    "\n",
    "                labels_found = 0\n",
    "                # WRITE RESULTS IN A FILE\n",
    "                for box in gt_list_boxes:\n",
    "                    if box[5]:\n",
    "                        labels_found = labels_found + 1\n",
    "\n",
    "                labels_found = 0\n",
    "                for counter, items in enumerate(list_ground_truth):\n",
    "                    labels_found = labels_found + correct_predicted[counter]\n",
    "\n",
    "                f_each.append(str(g_image_name)+\" ACCURACY of labels found: \"+str(labels_found/total_labels)+\"\\n\")\n",
    "\n",
    "                avg_acc = 0\n",
    "\n",
    "                for counter, items in enumerate(list_ground_truth):\n",
    "\n",
    "                    if items == 0:\n",
    "                        f_each.append(_get_label_from_id(counter)+ \"- Correct Predicted/labels in image:\"+ str(correct_predicted[counter]) + \"/\" + str(items) + \" = 0\\n\")\n",
    "                    else:\n",
    "                        f_each.append(_get_label_from_id(counter)+ \"- Correct Predicted/labels in image:\"+ str(correct_predicted[counter]) + \"/\" + str(items) + \" = \" +  str(correct_predicted[counter]/items) + \"\\n\")\n",
    "\n",
    "                    if predicted_per_label[counter] == 0:\n",
    "                        f_each.append(str(_get_label_from_id(counter))+ \"- Good predicted(TP)/total predicted(FP):\"+ str(correct_predicted[counter])+ \"/\"+str(predicted_per_label[counter])+\" = 0\\n\")\n",
    "                        f_each.append(str(_get_label_from_id(counter))+ \"- False predicted(FP)/total predicted(FP):\"+ str(predicted_per_label[counter] - correct_predicted[counter])+ \"/\"+str(predicted_per_label[counter])+\" = 0\\n\")\n",
    "                    else:\n",
    "                        f_each.append(str(_get_label_from_id(counter))+ \"- Good predicted(TP)/total predicted:\"+ str(correct_predicted[counter]) + \"/\"+str(predicted_per_label[counter])+\" = \"+ str(correct_predicted[counter]/predicted_per_label[counter]) + \"\\n\")\n",
    "                        f_each.append(str(_get_label_from_id(counter))+ \"- False predicted(FP)/total predicted:\"+ str(predicted_per_label[counter] - correct_predicted[counter]) + \"/\"+str(predicted_per_label[counter])+\" = \"+ str((predicted_per_label[counter] - correct_predicted[counter])/predicted_per_label[counter]) + \"\\n\")\n",
    "\n",
    "\n",
    "                    if predicted_per_label[counter] > 0 and items == 0:\n",
    "                        f_each.append(str(_get_label_from_id(counter))+ \"- Accuracy: 0 \\n\")\n",
    "                        label_avg_acc = 0\n",
    "                        avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train = _adding_avg_label_from_id(counter, 0, avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train)\n",
    "                    elif predicted_per_label[counter] == 0 and items > 0:\n",
    "                        f_each.append(str(_get_label_from_id(counter))+ \"- Accuracy: 0 \\n\")\n",
    "                        label_avg_acc = 0\n",
    "                        avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train = _adding_avg_label_from_id(counter, 0, avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train)\n",
    "                    elif predicted_per_label[counter] == 0 and items == 0:\n",
    "                        f_each.append(str(_get_label_from_id(counter))+ \"- Accuracy: 0 \\n\")\n",
    "                        avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train = _adding_avg_label_from_id(counter, 100, avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train)\n",
    "                        label_avg_acc = 0\n",
    "                    else: # It has predicted correctly that there are any label of the object searched\n",
    "                        f_each.append(str(_get_label_from_id(counter))+ \"- Accuracy: \" + str((correct_predicted[counter]/items)*100) + \" \\n\")\n",
    "                        label_avg_acc = (correct_predicted[counter]/items)*100\n",
    "                        avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train = _adding_avg_label_from_id(counter, ((correct_predicted[counter]/items)*100), avg_acc_per_traffic_sign, avg_acc_per_traffic_light, avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train)\n",
    "\n",
    "                    avg_acc = avg_acc + label_avg_acc\n",
    "                    f_each.append(\"---\\n\")\n",
    "\n",
    "                f_each.append(str(g_image_name)+\" AVERAGE ACCURACY: \"+str(avg_acc/10)+\"\\n\")\n",
    "                average_accuracy.append(avg_acc/10)\n",
    "\n",
    "                f_each.append(\"--------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "            correct_predicted = [0,0,0,0,0,0,0,0,0,0]\n",
    "            predicted_per_label = [0,0,0,0,0,0,0,0,0,0]\n",
    "            g_image_name = listWords[3]\n",
    "\n",
    "            # ADD HERE THE INFORMATION LABELS OF THAT images\n",
    "            gt_list_boxes = _search_image_information(objects, g_image_name)\n",
    "        else:\n",
    "            # using remove() to\n",
    "            # perform removal\n",
    "            while(\"\" in listWords) :\n",
    "                listWords.remove(\"\")\n",
    "            current_object_label = listWords[0][:-1]\n",
    "\n",
    "            if current_object_label == \"traffi\":\n",
    "                current_object_label = \"traffic\" + \" \" + listWords[1][:-1]\n",
    "                count_traffic_label = 1\n",
    "            else:\n",
    "                count_traffic_label = 0\n",
    "\n",
    "\n",
    "            # 他の物体を認識したときはスルーする\n",
    "            if _get_id_label(current_object_label) == -1:\n",
    "                print(current_object_label)\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Left_x\n",
    "            left_x = listWords[2+count_traffic_label]\n",
    "\n",
    "            # top_y\n",
    "            top_y = listWords[4+count_traffic_label]\n",
    "\n",
    "            # width\n",
    "            width = listWords[6+count_traffic_label]\n",
    "\n",
    "            # height\n",
    "            height = listWords[8+count_traffic_label][:-2]\n",
    "\n",
    "            # Get the X-Y info\n",
    "            x1 = int(float(left_x))\n",
    "            y1 = int(float(top_y))\n",
    "            x2 = x1 + int(float(width))\n",
    "            y2 = y1 + int(float(height))\n",
    "\n",
    "            if abs(x1 - x2) < limit_box_range and abs(y1 - y2) < limit_box_range:\n",
    "                continue\n",
    "            total_predicted_per_label[_get_id_label(current_object_label)] = total_predicted_per_label[_get_id_label(current_object_label)] + 1\n",
    "            predicted_per_label[_get_id_label(current_object_label)] = predicted_per_label[_get_id_label(current_object_label)] + 1\n",
    "\n",
    "            position = -1\n",
    "            range = 200\n",
    "\n",
    "            for counter, box in enumerate(gt_list_boxes):\n",
    "                box_label= box[0]\n",
    "                box_x1 = box[1]\n",
    "                if box_label == current_object_label:\n",
    "                    if range >= abs(box_x1 - x1):\n",
    "                        range = abs(box_x1 - x1)\n",
    "                        position = counter\n",
    "\n",
    "            if position >= 0:\n",
    "                if gt_list_boxes[position][5] == False:\n",
    "\n",
    "                    gt_list_boxes[position][5] = True\n",
    "\n",
    "                    id = _get_id_label(current_object_label)\n",
    "                    correct_predicted[id] = correct_predicted[id] + 1\n",
    "                    total_correct_predicted[id] = total_correct_predicted[id] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _accuracy_count(total_GT_correct_predicted, avg_acc_per_traffic_sign, avg_acc_per_traffic_light, \n",
    "                                avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, \n",
    "                                avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train) -> None:\n",
    "\n",
    "    f_each.append(\"\\n\")\n",
    "    f_each.append(\"TOTAL\\n\")\n",
    "    f_each.append(\"--------------------------------------------------------------------\\n\")\n",
    "    f_each.append(\"Average accuracy: \" + str(_averageOfList(average_accuracy))+\"\\n\")\n",
    "\n",
    "    string_result_amount_labels = \"\"\n",
    "    string_result_acc = \"\"\n",
    "\n",
    "    for counter,amount_label in enumerate(total_GT_correct_predicted):\n",
    "\n",
    "        f_each.append(str(_get_label_from_id(counter)) +\"- Amount of labels: \" + str(amount_label) + \"\\n\")\n",
    "\n",
    "        if counter == 0:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_traffic_sign))+\"\\n\") \n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_traffic_sign)) + \",\"\n",
    "        elif counter == 1:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_traffic_light))+\"\\n\")\n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_traffic_light)) + \",\"\n",
    "        elif counter == 2:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_car))+\"\\n\")\n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_car)) + \",\"\n",
    "        elif counter == 3:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_rider))+\"\\n\")\n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_rider)) + \",\"\n",
    "        elif counter == 4:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_motor))+\"\\n\") \n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_motor)) + \",\"\n",
    "        elif counter == 5:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_person))+\"\\n\")\n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_person)) + \",\"\n",
    "        elif counter == 6:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_bus))+\"\\n\")\n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_bus)) + \",\"\n",
    "        elif counter == 7:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_truck))+\"\\n\")\n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_truck)) + \",\"\n",
    "        elif counter == 8:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_bike))+\"\\n\") \n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_bike)) + \",\"\n",
    "        elif counter == 9:\n",
    "            f_each.append(str(_get_label_from_id(counter)) +\"- Average accuracy: \" + str(_averageOfList(avg_acc_per_train))+\"\\n\")\n",
    "            string_result_acc = string_result_acc +  str(_averageOfList(avg_acc_per_train)) + \",\"\n",
    "\n",
    "        string_result_amount_labels = string_result_amount_labels + str(amount_label) + \",\"\n",
    "\n",
    "\n",
    "        f_each.append(\"---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _view_accuracy_label(total_GT_correct_predicted) -> None:\n",
    "\n",
    "    false_result = []\n",
    "\n",
    "    for index,amount_label in enumerate(total_predicted_per_label):\n",
    "        correct_buffer = total_correct_predicted[index]\n",
    "        false_buffer = 0\n",
    "\n",
    "        if amount_label > total_GT_correct_predicted[index]: \n",
    "            false_buffer = amount_label - correct_buffer\n",
    "        else:\n",
    "            false_buffer = total_GT_correct_predicted[index] - correct_buffer\n",
    "        false_result.append(false_buffer)\n",
    "\n",
    "        if correct_buffer == 0:\n",
    "            g_total_accuracy.append(0)\n",
    "        else:\n",
    "            g_total_accuracy.append( correct_buffer / (correct_buffer + false_buffer))\n",
    "\n",
    "    df = pd.DataFrame({'Name': [\"traffic sign\",\"traffic light\",\"car\",\"rider\",\"motor\",\"person\",\"bus\",\"truck\",\"bike\",\"train\"],\n",
    "                    'Original_data': total_GT_correct_predicted, \n",
    "                    'Predicted_num': total_predicted_per_label,\n",
    "                    'Predicted_correct_num': total_correct_predicted,\n",
    "                    'Predicted_false_num': false_result,\n",
    "                    'Accuracy': g_total_accuracy})\n",
    "    print(df)\n",
    "    # resourcesに追加\n",
    "    save_all_label_accuracy_csv(df)\n",
    "    save_all_label_accuracy_png(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワイルドカードを使ってファイルの削除\n",
    "def _remove_glob(pathname, recursive=True):\n",
    "    for p in glob.glob(pathname, recursive=recursive):\n",
    "        if os.path.isfile(p):\n",
    "            os.remove(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データの解凍\n",
    "def _load_image(file_path: str) -> np.ndarray:\n",
    "    with zipfile.ZipFile(file_path) as existing_zip:            \n",
    "\n",
    "        existing_zip.extractall('/tmp')\n",
    "\n",
    "        path_to_test_images_dir = pathlib.Path('/tmp')\n",
    "        test_image_path = sorted(list(path_to_test_images_dir.glob(\"*.jpg\")))\n",
    "        data = test_image_path\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'each_picture')\n",
    "def save_images(model, image_path_list, category_index, file_path: str=None) -> None:\n",
    "    makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "    \n",
    "    out_files = []\n",
    "    \n",
    "    for image_path in image_path_list:\n",
    "        \n",
    "        # the array based representation of the image will be used later in order to prepare the\n",
    "        # result image with boxes and labels on it.\n",
    "        image_np = np.array(Image.open(image_path))\n",
    "        # Actual detection.\n",
    "        output_dict = _run_inference_for_single_image(model, image_np)\n",
    "\n",
    "        tmp_image_name = 'Enter Image Path: ' + image_path.name\n",
    "        resultFile.append(tmp_image_name)\n",
    "\n",
    "        for index, item in enumerate(output_dict['detection_boxes']):\n",
    "            kind = output_dict['detection_classes'][index]\n",
    "            accuracy = output_dict['detection_scores'][index]\n",
    "            accuracy_int = int(accuracy * 100)\n",
    "\n",
    "            # boxの位置情報はymin、xmin、ymax、xmaxで、０～１の範囲\n",
    "            # imageは1280*720なので、x軸×1280、y軸×720\n",
    "            if accuracy_int >= 50:\n",
    "                left_x = int(output_dict['detection_boxes'][index][1] * 1280)\n",
    "                top_y = int(output_dict['detection_boxes'][index][0] * 780)\n",
    "                width = int(output_dict['detection_boxes'][index][3] * 1280)\n",
    "                height = int(output_dict['detection_boxes'][index][2] * 780)\n",
    "\n",
    "                kind_name = \"\"\n",
    "                if category_index[kind]['name'] == \"bicycle\":\n",
    "                            kind_name = \"bike\"\n",
    "                elif category_index[kind]['name'] == \"motorcycle\":\n",
    "                            kind_name = \"motor\"\n",
    "                else:\n",
    "                            kind_name = category_index[kind]['name']\n",
    "\n",
    "                tmp_buffer = kind_name + ': ' + str(accuracy_int) + '%\\t(left_x: ' + str(left_x) + \\\n",
    "                                        '\t top_y: ' + str(top_y) + '\t width: ' + str(width) + '\t height: ' + str(height) + ')'\n",
    "                resultFile.append(tmp_buffer)\n",
    "\n",
    "\n",
    "        # Visualization of the results of a detection.\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                output_dict['detection_boxes'],\n",
    "                output_dict['detection_classes'],\n",
    "                output_dict['detection_scores'],\n",
    "                category_index,\n",
    "                instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "                use_normalized_coordinates=True,\n",
    "                min_score_thresh=.5,\n",
    "                line_thickness=8)\n",
    "\n",
    "        predict_image = file_path.format(image_path.name[0:-4])\n",
    "        out_files.append(predict_image)\n",
    "        Image.fromarray(image_np).save(predict_image)\n",
    "\n",
    "    return out_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@resources(ait_output, path_helper, 'all_label_accuracy_csv')\n",
    "def save_all_label_accuracy_csv(df, file_path: str=None) -> None:\n",
    "    makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "    df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@resources(ait_output, path_helper, 'all_label_accuracy_png')\n",
    "def save_all_label_accuracy_png(df, file_path: str=None) -> None:\n",
    "    makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "    # 以前の画像ファイルがあれば削除\n",
    "    _remove_glob(str(Path(file_path).parent)+ '/*.png')\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 8), dpi=100)\n",
    "    ax = fig.subplots()\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    tmp_table = ax.table(cellText=df.values,\n",
    "        colLabels=df.columns,\n",
    "        rowLabels=df.index,\n",
    "        bbox=[0,0,1,1])\n",
    "    plt.savefig(file_path)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'each_label_accuracy')\n",
    "def save_each_label_accuracy(file_path: str=None) -> None:\n",
    "    makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for buf in f_each:\n",
    "            writer.writerow(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'traffic_sign_accuracy')\n",
    "def measure_traffic_sign_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'traffic_light_accuracy')\n",
    "def measure_traffic_light_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'car_accuracy')\n",
    "def measure_car_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'rider_accuracy')\n",
    "def measure_rider_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'motor_accuracy')\n",
    "def measure_motor_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'person_accuracy')\n",
    "def measure_person_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'bus_accuracy')\n",
    "def measure_bus_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'truck_accuracy')\n",
    "def measure_truck_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'bike_accuracy')\n",
    "def measure_bike_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'train_accuracy')\n",
    "def measure_train_accuracy(accuracy):\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:functions\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'Log')\n",
    "def move_log(file_path: str=None) -> None:\n",
    "    makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "\n",
    "    shutil.move(get_log_path(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:main\n",
    "# should edit\n",
    "#########################################\n",
    "\n",
    "@log(logger)\n",
    "@ait_main(ait_output, path_helper)\n",
    "def main() -> None:\n",
    "\n",
    "    # インベントリのMNISTラベル・画像を読み込み\n",
    "    image_path = ait_input.get_inventory_path('test_set_images')\n",
    "    \n",
    "    model_checkpoint_path = ait_input.get_inventory_path('trained_model_checkpoint')\n",
    "    model_graph_path = ait_input.get_inventory_path('trained_model_graph')\n",
    "    model_protobuf_path = ait_input.get_inventory_path('trained_model_protobuf')\n",
    "\n",
    "    # モデル読み込み\n",
    "    zipfile.ZipFile(model_checkpoint_path).extractall('/tmp')\n",
    "    zipfile.ZipFile(model_graph_path).extractall('/tmp/ssd_mobilenet_v2_coco')\n",
    "    zipfile.ZipFile(model_protobuf_path).extractall('/tmp/ssd_mobilenet_v2_coco')\n",
    "    model = tf.saved_model.load(str('/tmp/ssd_mobilenet_v2_coco/saved_model'))\n",
    "    \n",
    "    # jsonファイルのパス\n",
    "    jsonFileName = ait_input.get_inventory_path('test_set_labels')\n",
    "    objects = _read_labels(jsonFileName)\n",
    "\n",
    "    # ラベルの定義読み込み\n",
    "    label_map_name = ait_input.get_inventory_path('labels_define')\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(label_map_name, use_display_name=True)\n",
    "    \n",
    "    # 画像読み込み\n",
    "    image_list = _load_image(image_path)\n",
    "    \n",
    "\n",
    "    # 推論 (resources)\n",
    "    save_images(model, image_list, category_index)\n",
    "\n",
    "    resultFile.append('Enter Image Path: END')\n",
    "\n",
    "    # JSONファイルと推論結果を比較する\n",
    "    _compare_json(gt_list_boxes, objects, total_GT_correct_predicted, avg_acc_per_traffic_sign, avg_acc_per_traffic_light, \n",
    "                                avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, \n",
    "                                avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train)\n",
    "    # 推論結果の集計\n",
    "    _accuracy_count(total_GT_correct_predicted, avg_acc_per_traffic_sign, avg_acc_per_traffic_light, \n",
    "                                avg_acc_per_car, avg_acc_per_rider, avg_acc_per_motor, avg_acc_per_person, \n",
    "                                avg_acc_per_bus, avg_acc_per_truck, avg_acc_per_bike, avg_acc_per_train)\n",
    "    # label毎に確率を集計 (resources)\n",
    "    _view_accuracy_label(total_GT_correct_predicted)\n",
    "    \n",
    "    # download\n",
    "    save_each_label_accuracy()\n",
    "\n",
    "    # measure\n",
    "    measure_traffic_sign_accuracy(g_total_accuracy[0])\n",
    "    measure_traffic_light_accuracy(g_total_accuracy[1])\n",
    "    measure_car_accuracy(g_total_accuracy[2])\n",
    "    measure_rider_accuracy(g_total_accuracy[3])\n",
    "    measure_motor_accuracy(g_total_accuracy[4])\n",
    "    measure_person_accuracy(g_total_accuracy[5])\n",
    "    measure_bus_accuracy(g_total_accuracy[6])\n",
    "    measure_truck_accuracy(g_total_accuracy[7])\n",
    "    measure_bike_accuracy(g_total_accuracy[8])\n",
    "    measure_train_accuracy(g_total_accuracy[9])\n",
    "\n",
    "    \n",
    "    move_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name  Original_data  Predicted_num  Predicted_correct_num  \\\n",
      "0   traffic sign             40              0                      0   \n",
      "1  traffic light             51              3                      3   \n",
      "2            car             88             35                     32   \n",
      "3          rider              8              0                      0   \n",
      "4          motor              5              1                      1   \n",
      "5         person             39             14                     11   \n",
      "6            bus              5              4                      2   \n",
      "7          truck              2              2                      1   \n",
      "8           bike              6              1                      1   \n",
      "9          train              0              0                      0   \n",
      "\n",
      "   Predicted_false_num  Accuracy  \n",
      "0                   40  0.000000  \n",
      "1                   48  0.058824  \n",
      "2                   56  0.363636  \n",
      "3                    8  0.000000  \n",
      "4                    4  0.200000  \n",
      "5                   28  0.282051  \n",
      "6                    3  0.400000  \n",
      "7                    1  0.500000  \n",
      "8                    5  0.166667  \n",
      "9                    0  0.000000  \n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# area:entory point\n",
    "# do not edit\n",
    "#########################################\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:license attribute set\n",
    "# should edit\n",
    "#########################################\n",
    "ait_owner='AIST'\n",
    "ait_creation_year='2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# area:prepare deproy\n",
    "# do not edit\n",
    "#########################################\n",
    "\n",
    "if not is_ait_launch:\n",
    "    from ait_sdk.deploy import prepare_deploy\n",
    "    from ait_sdk.license.license_generator import LicenseGenerator\n",
    "    \n",
    "    current_dir = %pwd\n",
    "    prepare_deploy(ait_manifest, ait_sdk_name, current_dir, requirements_path, is_remote_deploy=True)\n",
    "    \n",
    "    # output License.txt\n",
    "    license_generator = LicenseGenerator()\n",
    "    license_generator.write('../top_dir/LICENSE.txt', ait_creation_year, ait_owner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
